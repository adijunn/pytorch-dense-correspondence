{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting CUDA_VISIBLE_DEVICES =  3,\n"
     ]
    }
   ],
   "source": [
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "utils.add_dense_correspondence_to_python_path()\n",
    "from dense_correspondence.training.training import *\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# utils.set_default_cuda_visible_devices()\n",
    "utils.set_cuda_visible_devices([3]) # use this to manually set CUDA_VISIBLE_DEVICES\n",
    "\n",
    "from dense_correspondence.training.training import DenseCorrespondenceTraining\n",
    "from dense_correspondence.dataset.spartan_dataset_masked import SpartanDataset\n",
    "from dense_correspondence.evaluation.evaluation import DenseCorrespondenceEvaluation\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the configuration for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene directory: /home/adi/code/data_volume/fabric_data/logs_proto/tier13_oracle_2111/processed\n",
      "Using SpartanDataset:\n",
      "   - in train mode\n",
      "   - number of scenes 1\n",
      "   - total images:     2112\n",
      "{'logs_root_path': 'code/data_volume/fabric_data/logs_proto', 'single_object_scenes_config_files': ['tier13_oracle_2111.yaml'], 'multi_object_scenes_config_files': []}\n"
     ]
    }
   ],
   "source": [
    "config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'dataset', 'composite', 'tier13_oracle_2111_only.yaml')\n",
    "config = utils.getDictFromYamlFilename(config_filename)\n",
    "\n",
    "train_config_file = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence', \n",
    "                               'training', 'training.yaml')\n",
    "\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)\n",
    "dataset = SpartanDataset(config=config)\n",
    "\n",
    "logging_dir = \"code/data_volume/fabric_data/trained_models/tutorials\"\n",
    "num_iterations = 3500\n",
    "d = 3 # the descriptor dimension\n",
    "normalize = True\n",
    "name = \"tier13_oracle_2111_distributional_loss_%d\" %(d)\n",
    "train_config[\"training\"][\"logging_dir_name\"] = name\n",
    "train_config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train_config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "train_config[\"dense_correspondence_network\"][\"normalize\"] = normalize\n",
    "train_config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "\n",
    "TRAIN = True\n",
    "EVALUATE = False\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading knots info for scene tier13_oracle_2111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training descriptor of dimension 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:enabling domain randomization\n",
      "INFO:root:setting up tensorboard_logger\n",
      "INFO:root:tensorboard logger started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using SINGLE_OBJECT_WITHIN_SCENE\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:2562: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(375.1143, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1 took 1.794 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(376.7976, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(321.1715, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(254.9813, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 4 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(317.7393, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 5 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(251.8228, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 6 took 1.712 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(241.0924, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 7 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(215.5749, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 8 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(200.8605, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 9 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 10 of 3500\n",
      "INFO:root:single iteration took 1.735 seconds\n",
      "INFO:root:Training is 0 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(203.7799, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 10 took 1.735 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(235.8568, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 11 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(215.4619, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 12 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(201.4158, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 13 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(261.6435, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 14 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(232.4509, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 15 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(191.2890, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 16 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(240.7251, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 17 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(180.7689, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 18 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(207.7365, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 19 took 1.734 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 20 of 3500\n",
      "INFO:root:single iteration took 1.671 seconds\n",
      "INFO:root:Training is 0 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(193.0593, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 20 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(201.9729, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 21 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(214.1720, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 22 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(179.9345, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 23 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(190.4387, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 24 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(183.6759, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 25 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(216.1801, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 26 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(174.9054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 27 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(179.1686, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 28 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(254.0567, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 29 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 30 of 3500\n",
      "INFO:root:single iteration took 1.685 seconds\n",
      "INFO:root:Training is 0 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(180.3532, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 30 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(190.8702, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 31 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(171.3810, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 32 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(215.1772, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 33 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(180.9046, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 34 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(169.8235, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 35 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(172.9004, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 36 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(167.6466, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 37 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(161.5148, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 38 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(160.7440, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 39 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 40 of 3500\n",
      "INFO:root:single iteration took 1.673 seconds\n",
      "INFO:root:Training is 1 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(161.7419, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 40 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(169.2023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 41 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(162.7066, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 42 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(159.8588, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 43 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(166.7119, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 44 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(163.0962, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 45 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(153.2647, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 46 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(160.5606, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 47 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(192.8400, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 48 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(165.2786, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 49 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 50 of 3500\n",
      "INFO:root:single iteration took 1.677 seconds\n",
      "INFO:root:Training is 1 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(195.6460, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 50 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(171.6815, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 51 took 1.717 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(158.6573, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 52 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(161.7854, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 53 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(155.3599, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 54 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(163.2265, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 55 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(162.0959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 56 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(155.7965, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 57 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(160.0572, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 58 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(176.6481, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 59 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 60 of 3500\n",
      "INFO:root:single iteration took 1.633 seconds\n",
      "INFO:root:Training is 1 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(134.6634, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 60 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(156.9647, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 61 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(159.8571, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 62 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(164.8614, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 63 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(157.1518, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 64 took 1.636 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(161.7719, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 65 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.6099, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 66 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(153.9886, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 67 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.5515, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 68 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(153.8491, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 69 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 70 of 3500\n",
      "INFO:root:single iteration took 1.640 seconds\n",
      "INFO:root:Training is 2 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(152.5838, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 70 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(152.5790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 71 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(146.7408, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 72 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(155.4275, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 73 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(149.4151, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 74 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.9700, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 75 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(148.4037, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 76 took 1.723 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(167.3083, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 77 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.3571, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 78 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.3958, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 79 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 80 of 3500\n",
      "INFO:root:single iteration took 1.613 seconds\n",
      "INFO:root:Training is 2 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(154.8702, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 80 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.7564, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 81 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.7744, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 82 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(157.6715, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 83 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(148.5486, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 84 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(155.2817, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 85 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.3449, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 86 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.3881, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 87 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(146.0129, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 88 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(143.3198, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 89 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 90 of 3500\n",
      "INFO:root:single iteration took 1.689 seconds\n",
      "INFO:root:Training is 2 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(169.1051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 90 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.7261, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 91 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.3654, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 92 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.1910, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 93 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.9285, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 94 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.8041, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 95 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(151.5544, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 96 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.7059, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 97 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.5700, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 98 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(143.4967, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 99 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 100 of 3500\n",
      "INFO:root:single iteration took 1.650 seconds\n",
      "INFO:root:Training is 2 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(145.0741, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 100 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.1233, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 101 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(149.8178, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 102 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.7657, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 103 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.1293, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 104 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.7992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 105 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.0746, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 106 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0308, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 107 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.7849, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 108 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.8532, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 109 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 110 of 3500\n",
      "INFO:root:single iteration took 1.632 seconds\n",
      "INFO:root:Training is 3 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(133.0613, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 110 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(158.0815, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 111 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.7933, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 112 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(149.7700, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 113 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(173.8623, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 114 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(149.2557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 115 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(151.0273, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 116 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.6220, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 117 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.5374, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 118 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.2235, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 119 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 120 of 3500\n",
      "INFO:root:single iteration took 1.660 seconds\n",
      "INFO:root:Training is 3 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(145.9938, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 120 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.2307, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 121 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.1290, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 122 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.3619, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 123 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(165.5559, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 124 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(202.0642, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 125 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.8140, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 126 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.8860, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 127 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(153.0446, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 128 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.6491, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 129 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 130 of 3500\n",
      "INFO:root:single iteration took 1.656 seconds\n",
      "INFO:root:Training is 3 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(137.9309, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 130 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(155.8700, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 131 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.6773, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 132 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.5758, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 133 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(160.1664, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 134 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(154.0239, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 135 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.3676, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 136 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.4784, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 137 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(159.3420, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 138 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6836, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 139 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 140 of 3500\n",
      "INFO:root:single iteration took 1.693 seconds\n",
      "INFO:root:Training is 4 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(137.1915, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 140 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.7664, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 141 took 1.719 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(153.2060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 142 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.8803, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 143 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.6419, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 144 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.8219, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 145 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.0451, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 146 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(174.7475, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 147 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(144.9548, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 148 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(149.9715, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 149 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 150 of 3500\n",
      "INFO:root:single iteration took 1.690 seconds\n",
      "INFO:root:Training is 4 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(130.8560, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 150 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.1797, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 151 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.6251, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 152 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.7109, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 153 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(151.4443, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 154 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(163.8098, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 155 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(146.0907, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 156 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.0819, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 157 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.6919, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 158 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.3789, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 159 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 160 of 3500\n",
      "INFO:root:single iteration took 1.684 seconds\n",
      "INFO:root:Training is 4 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(137.9513, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 160 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.1974, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 161 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.0781, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 162 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.0976, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 163 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.7606, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 164 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.8500, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 165 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(148.3166, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 166 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.6202, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 167 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.8710, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 168 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.7777, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 169 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 170 of 3500\n",
      "INFO:root:single iteration took 1.691 seconds\n",
      "INFO:root:Training is 4 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(161.9156, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 170 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.4076, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 171 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.5937, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 172 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.3523, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 173 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8501, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 174 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.9307, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 175 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.2163, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 176 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(149.9833, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 177 took 1.733 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(146.3355, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 178 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.4443, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 179 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 180 of 3500\n",
      "INFO:root:single iteration took 1.640 seconds\n",
      "INFO:root:Training is 5 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(137.2131, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 180 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.5782, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 181 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.2043, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 182 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(206.6143, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 183 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.7002, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 184 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.2280, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 185 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.0408, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 186 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.4107, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 187 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.3291, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 188 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.1775, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 189 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 190 of 3500\n",
      "INFO:root:single iteration took 1.645 seconds\n",
      "INFO:root:Training is 5 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(157.8961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 190 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.4496, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 191 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(149.1426, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 192 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.6181, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 193 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.3064, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 194 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.2743, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 195 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(146.3787, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 196 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.7474, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 197 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.6373, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 198 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.2862, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 199 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 200 of 3500\n",
      "INFO:root:single iteration took 1.681 seconds\n",
      "INFO:root:Training is 5 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(151.4056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 200 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.8610, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 201 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.1508, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 202 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.4387, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 203 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.1046, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 204 took 1.714 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.4198, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 205 took 1.719 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.9502, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 206 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.2000, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 207 took 1.803 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.8045, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 208 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.8646, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 209 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 210 of 3500\n",
      "INFO:root:single iteration took 1.680 seconds\n",
      "INFO:root:Training is 6 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(127.9527, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 210 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.3455, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 211 took 1.717 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.9967, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 212 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.9052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 213 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.0260, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 214 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.9264, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 215 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.9650, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 216 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0103, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 217 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.1626, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 218 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.1442, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 219 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 220 of 3500\n",
      "INFO:root:single iteration took 1.674 seconds\n",
      "INFO:root:Training is 6 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(134.7945, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 220 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.1231, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 221 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.5400, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 222 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.9779, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 223 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.0291, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 224 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(161.4790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 225 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.9742, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 226 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2390, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 227 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.9704, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 228 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.3075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 229 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 230 of 3500\n",
      "INFO:root:single iteration took 1.694 seconds\n",
      "INFO:root:Training is 6 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(129.2995, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 230 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.8279, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 231 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5371, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 232 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.9828, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 233 took 1.719 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.9123, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 234 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.4092, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 235 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.7797, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 236 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.6521, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 237 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.0922, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 238 took 1.723 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.8954, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 239 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 240 of 3500\n",
      "INFO:root:single iteration took 1.616 seconds\n",
      "INFO:root:Training is 6 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(133.8156, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 240 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(153.7351, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 241 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(157.1574, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 242 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.5061, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 243 took 1.624 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.5348, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 244 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4313, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 245 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(143.6356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 246 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0443, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 247 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.1455, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 248 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.4114, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 249 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 250 of 3500\n",
      "INFO:root:single iteration took 1.640 seconds\n",
      "INFO:root:Training is 7 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(130.2706, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 250 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.6656, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 251 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(164.0437, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 252 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5522, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 253 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.0367, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 254 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(151.4829, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 255 took 1.629 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(173.1384, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 256 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.1421, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 257 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3216, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 258 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(154.2017, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 259 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 260 of 3500\n",
      "INFO:root:single iteration took 1.640 seconds\n",
      "INFO:root:Training is 7 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(135.7636, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 260 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1674, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 261 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5438, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 262 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8618, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 263 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.0146, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 264 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.5875, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 265 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.1051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 266 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.1291, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 267 took 1.636 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.8450, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 268 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.1689, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 269 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 270 of 3500\n",
      "INFO:root:single iteration took 1.647 seconds\n",
      "INFO:root:Training is 7 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(143.7922, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 270 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.6191, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 271 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.0524, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 272 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.8513, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 273 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.5994, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 274 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.2183, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 275 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9750, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 276 took 1.629 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8375, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 277 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.4695, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 278 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.0367, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 279 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 280 of 3500\n",
      "INFO:root:single iteration took 1.650 seconds\n",
      "INFO:root:Training is 8 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(128.1251, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 280 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.0766, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 281 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.4660, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 282 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4531, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 283 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.4699, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 284 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.0247, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 285 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.6228, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 286 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(143.0052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 287 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.6185, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 288 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0540, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 289 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 290 of 3500\n",
      "INFO:root:single iteration took 1.632 seconds\n",
      "INFO:root:Training is 8 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(129.2527, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 290 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(154.2066, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 291 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.1004, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 292 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.7952, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 293 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.5301, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 294 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.2083, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 295 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.4859, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 296 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.1570, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 297 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1642, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 298 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.3349, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 299 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 300 of 3500\n",
      "INFO:root:single iteration took 1.688 seconds\n",
      "INFO:root:Training is 8 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(133.8769, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 300 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1226, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 301 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.9229, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 302 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3440, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 303 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0101, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 304 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.5598, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 305 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9941, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 306 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.6106, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 307 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.2609, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 308 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(155.2966, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 309 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 310 of 3500\n",
      "INFO:root:single iteration took 1.710 seconds\n",
      "INFO:root:Training is 8 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(136.1925, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 310 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4318, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 311 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.4393, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 312 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4600, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 313 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(144.3769, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 314 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(144.1300, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 315 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.7524, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 316 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.6874, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 317 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.3927, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 318 took 1.711 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.2119, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 319 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 320 of 3500\n",
      "INFO:root:single iteration took 1.689 seconds\n",
      "INFO:root:Training is 9 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(135.0893, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 320 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3558, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 321 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.8227, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 322 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8545, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 323 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6473, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 324 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(158.9910, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 325 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.8170, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 326 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.0056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 327 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.8693, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 328 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.8580, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 329 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 330 of 3500\n",
      "INFO:root:single iteration took 1.664 seconds\n",
      "INFO:root:Training is 9 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(128.8307, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 330 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2263, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 331 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.3151, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 332 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(143.6238, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 333 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.6932, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 334 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.9208, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 335 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.9003, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 336 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.2890, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 337 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.0234, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 338 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.4533, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 339 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 340 of 3500\n",
      "INFO:root:single iteration took 1.670 seconds\n",
      "INFO:root:Training is 9 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(129.3972, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 340 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.0989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 341 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.7849, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 342 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2678, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 343 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(143.2246, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 344 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.5249, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 345 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3548, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 346 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.2604, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 347 took 1.733 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.2507, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 348 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.0851, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 349 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 350 of 3500\n",
      "INFO:root:single iteration took 1.662 seconds\n",
      "INFO:root:Training is 10 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(125.2808, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 350 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.4515, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 351 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.0528, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 352 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.3556, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 353 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1824, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 354 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(167.8882, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 355 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2503, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 356 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.1504, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 357 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3371, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 358 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3331, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 359 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 360 of 3500\n",
      "INFO:root:single iteration took 1.679 seconds\n",
      "INFO:root:Training is 10 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(130.4947, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 360 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.0513, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 361 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.4758, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 362 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3235, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 363 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 364 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1161, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 365 took 1.579 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3025, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 366 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.2269, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 367 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.9261, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 368 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.1260, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 369 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 370 of 3500\n",
      "INFO:root:single iteration took 1.574 seconds\n",
      "INFO:root:Training is 10 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(131.8079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 370 took 1.574 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.5645, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 371 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8568, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 372 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8778, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 373 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8201, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 374 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.9851, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 375 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9183, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 376 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.4406, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 377 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4716, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 378 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.9148, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 379 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 380 of 3500\n",
      "INFO:root:single iteration took 1.602 seconds\n",
      "INFO:root:Training is 10 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(129.1098, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 380 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1741, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 381 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1988, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 382 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.7806, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 383 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(148.5285, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 384 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7719, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 385 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.8867, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 386 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.7666, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 387 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3589, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 388 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.6262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 389 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 390 of 3500\n",
      "INFO:root:single iteration took 1.697 seconds\n",
      "INFO:root:Training is 11 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(128.2836, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 390 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.4141, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 391 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5289, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 392 took 1.572 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1219, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 393 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.5333, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 394 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8536, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 395 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.1540, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 396 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.7752, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 397 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8824, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 398 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9902, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 399 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 400 of 3500\n",
      "INFO:root:single iteration took 1.589 seconds\n",
      "INFO:root:Training is 11 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.9075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 400 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.5326, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 401 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.4118, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 402 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.1695, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 403 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.5851, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 404 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1697, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 405 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.1481, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 406 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.9445, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 407 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.5361, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 408 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1675, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 409 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 410 of 3500\n",
      "INFO:root:single iteration took 1.614 seconds\n",
      "INFO:root:Training is 11 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(130.6150, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 410 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.2697, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 411 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6958, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 412 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.0498, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 413 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.5360, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 414 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.0732, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 415 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.6856, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 416 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.8765, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 417 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.5315, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 418 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.2372, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 419 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 420 of 3500\n",
      "INFO:root:single iteration took 1.599 seconds\n",
      "INFO:root:Training is 12 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.5269, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 420 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.2208, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 421 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6509, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 422 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.6322, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 423 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.4930, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 424 took 1.786 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.6109, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 425 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8561, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 426 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.0459, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 427 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.8953, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 428 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 429 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 430 of 3500\n",
      "INFO:root:single iteration took 1.629 seconds\n",
      "INFO:root:Training is 12 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.2881, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 430 took 1.629 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.8897, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 431 took 1.636 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 432 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4599, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 433 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5649, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 434 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.9141, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 435 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.0817, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 436 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.2184, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 437 took 1.725 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4828, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 438 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.2148, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 439 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 440 of 3500\n",
      "INFO:root:single iteration took 1.629 seconds\n",
      "INFO:root:Training is 12 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.0878, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 440 took 1.629 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.1070, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 441 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.8749, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 442 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.0360, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 443 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.6336, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 444 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.2022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 445 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.6943, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 446 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7862, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 447 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.6143, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 448 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6641, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 449 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 450 of 3500\n",
      "INFO:root:single iteration took 1.699 seconds\n",
      "INFO:root:Training is 12 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.1359, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 450 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.2186, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 451 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.8248, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 452 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7082, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 453 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.8339, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 454 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.2309, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 455 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6455, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 456 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1324, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 457 took 1.779 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(144.5757, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 458 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7396, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 459 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 460 of 3500\n",
      "INFO:root:single iteration took 1.681 seconds\n",
      "INFO:root:Training is 13 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(146.4325, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 460 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6965, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 461 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.5726, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 462 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3330, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 463 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.8714, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 464 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1902, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 465 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(222.7547, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 466 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4460, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 467 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.1216, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 468 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6085, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 469 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 470 of 3500\n",
      "INFO:root:single iteration took 1.652 seconds\n",
      "INFO:root:Training is 13 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(133.3577, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 470 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6279, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 471 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9394, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 472 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.3110, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 473 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0426, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 474 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5751, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 475 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3860, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 476 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7713, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 477 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5656, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 478 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(191.2669, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 479 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 480 of 3500\n",
      "INFO:root:single iteration took 1.685 seconds\n",
      "INFO:root:Training is 13 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(141.6236, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 480 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7246, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 481 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0424, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 482 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8749, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 483 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.4061, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 484 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(159.8678, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 485 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.1862, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 486 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0321, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 487 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0291, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 488 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.9211, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 489 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 490 of 3500\n",
      "INFO:root:single iteration took 1.680 seconds\n",
      "INFO:root:Training is 14 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.1834, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 490 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(147.4445, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 491 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.0107, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 492 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.9795, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 493 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2716, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 494 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.5437, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 495 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.7106, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 496 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.1753, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 497 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.2814, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 498 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5456, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 499 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4259, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 500 took 1.630 seconds\n",
      "logging train loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 500 of 3500\n",
      "INFO:root:single iteration took 1.630 seconds\n",
      "INFO:root:Training is 14 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.4284, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 501 took 1.574 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.4613, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 502 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.0505, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 503 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.0607, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 504 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 505 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8622, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 506 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.5214, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 507 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6845, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 508 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.4824, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 509 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 510 of 3500\n",
      "INFO:root:single iteration took 1.599 seconds\n",
      "INFO:root:Training is 14 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.2647, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 510 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6406, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 511 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.3156, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 512 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 513 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5186, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 514 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3503, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 515 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5648, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 516 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9622, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 517 took 1.628 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1755, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 518 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5494, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 519 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 520 of 3500\n",
      "INFO:root:single iteration took 1.598 seconds\n",
      "INFO:root:Training is 14 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.6494, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 520 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7883, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 521 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.6639, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 522 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.4278, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 523 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9746, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 524 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.7309, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 525 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.4870, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 526 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5337, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 527 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.9188, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 528 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.6850, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 529 took 1.624 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 530 of 3500\n",
      "INFO:root:single iteration took 1.617 seconds\n",
      "INFO:root:Training is 15 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(140.9111, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 530 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.8121, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 531 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3993, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 532 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0522, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 533 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6385, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 534 took 1.712 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2581, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 535 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.2188, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 536 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.9601, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 537 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6896, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 538 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.7264, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 539 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 540 of 3500\n",
      "INFO:root:single iteration took 1.603 seconds\n",
      "INFO:root:Training is 15 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.4375, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 540 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7261, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 541 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7960, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 542 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8193, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 543 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5825, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 544 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.8136, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 545 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.7706, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 546 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1166, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 547 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.9810, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 548 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.4482, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 549 took 1.781 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 550 of 3500\n",
      "INFO:root:single iteration took 1.589 seconds\n",
      "INFO:root:Training is 15 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(131.3523, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 550 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7216, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 551 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3292, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 552 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.8315, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 553 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7855, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 554 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8644, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 555 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.8893, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 556 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5215, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 557 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5035, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 558 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3317, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 559 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 560 of 3500\n",
      "INFO:root:single iteration took 1.604 seconds\n",
      "INFO:root:Training is 16 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(133.0010, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 560 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.5757, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 561 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(155.3324, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 562 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8128, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 563 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7413, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 564 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2776, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 565 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(143.2726, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 566 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9838, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 567 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6365, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 568 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0902, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 569 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 570 of 3500\n",
      "INFO:root:single iteration took 1.572 seconds\n",
      "INFO:root:Training is 16 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.7311, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 570 took 1.572 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9382, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 571 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8448, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 572 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1562, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 573 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.7974, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 574 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 575 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 576 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2243, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 577 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8360, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 578 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4785, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 579 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 580 of 3500\n",
      "INFO:root:single iteration took 1.607 seconds\n",
      "INFO:root:Training is 16 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(129.2263, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 580 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2456, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 581 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0618, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 582 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.1488, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 583 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.5305, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 584 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0344, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 585 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9295, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 586 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.0319, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 587 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0983, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 588 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4776, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 589 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 590 of 3500\n",
      "INFO:root:single iteration took 1.594 seconds\n",
      "INFO:root:Training is 16 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.5707, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 590 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(143.1794, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 591 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3308, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 592 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5894, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 593 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.7332, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 594 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2551, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 595 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7631, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 596 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8622, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 597 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.1823, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 598 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7660, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 599 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 600 of 3500\n",
      "INFO:root:single iteration took 1.617 seconds\n",
      "INFO:root:Training is 17 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(134.7023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 600 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5251, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 601 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0861, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 602 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4671, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 603 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.6271, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 604 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3753, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 605 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.5104, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 606 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2979, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 607 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.5246, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 608 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.3283, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 609 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 610 of 3500\n",
      "INFO:root:single iteration took 1.584 seconds\n",
      "INFO:root:Training is 17 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.9901, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 610 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5582, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 611 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.9843, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 612 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.2144, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 613 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 614 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.5535, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 615 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.9292, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 616 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.2314, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 617 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3430, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 618 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.1262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 619 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 620 of 3500\n",
      "INFO:root:single iteration took 1.581 seconds\n",
      "INFO:root:Training is 17 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(131.5258, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 620 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.2543, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 621 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.4334, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 622 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.9373, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 623 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9279, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 624 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.6571, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 625 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1425, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 626 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.2822, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 627 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8445, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 628 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6951, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 629 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 630 of 3500\n",
      "INFO:root:single iteration took 1.627 seconds\n",
      "INFO:root:Training is 18 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.7906, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 630 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4782, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 631 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 632 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(148.5594, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 633 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6584, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 634 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.7990, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 635 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.1797, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 636 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.0841, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 637 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2615, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 638 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0607, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 639 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 640 of 3500\n",
      "INFO:root:single iteration took 1.595 seconds\n",
      "INFO:root:Training is 18 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(145.4311, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 640 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.9234, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 641 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8976, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 642 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.7361, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 643 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0297, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 644 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6841, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 645 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.7544, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 646 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5777, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 647 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1064, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 648 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.3093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 649 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 650 of 3500\n",
      "INFO:root:single iteration took 1.578 seconds\n",
      "INFO:root:Training is 18 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.1032, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 650 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.1364, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 651 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8734, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 652 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.3211, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 653 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2657, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 654 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6957, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 655 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.2112, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 656 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.6527, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 657 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.8381, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 658 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.4988, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 659 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 660 of 3500\n",
      "INFO:root:single iteration took 1.601 seconds\n",
      "INFO:root:Training is 18 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(130.8601, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 660 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3851, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 661 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3304, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 662 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1857, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 663 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.4375, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 664 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4297, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 665 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.2158, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 666 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 667 took 1.569 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.1371, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 668 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.1529, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 669 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 670 of 3500\n",
      "INFO:root:single iteration took 1.614 seconds\n",
      "INFO:root:Training is 19 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.8019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 670 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1448, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 671 took 1.569 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7127, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 672 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.7931, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 673 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3084, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 674 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0296, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 675 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.7402, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 676 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8505, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 677 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.0822, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 678 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.3977, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 679 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 680 of 3500\n",
      "INFO:root:single iteration took 1.568 seconds\n",
      "INFO:root:Training is 19 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.4165, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 680 took 1.568 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7743, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 681 took 1.574 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3837, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 682 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.8706, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 683 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7761, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 684 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.0833, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 685 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(148.9519, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 686 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.0568, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 687 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7158, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 688 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6856, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 689 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 690 of 3500\n",
      "INFO:root:single iteration took 1.610 seconds\n",
      "INFO:root:Training is 19 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(128.0500, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 690 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.2115, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 691 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.8549, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 692 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8012, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 693 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1438, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 694 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.4735, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 695 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(154.4049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 696 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7954, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 697 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6584, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 698 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.1836, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 699 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 700 of 3500\n",
      "INFO:root:single iteration took 1.606 seconds\n",
      "INFO:root:Training is 20 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.6753, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 700 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9547, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 701 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6021, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 702 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7673, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 703 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3651, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 704 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7457, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 705 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.7798, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 706 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.1094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 707 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.1276, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 708 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.1345, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 709 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 710 of 3500\n",
      "INFO:root:single iteration took 1.693 seconds\n",
      "INFO:root:Training is 20 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(131.9209, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 710 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4513, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 711 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5303, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 712 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6617, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 713 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6248, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 714 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.1353, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 715 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0608, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 716 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.9718, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 717 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4437, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 718 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8088, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 719 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 720 of 3500\n",
      "INFO:root:single iteration took 1.614 seconds\n",
      "INFO:root:Training is 20 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(129.2904, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 720 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5459, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 721 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.7549, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 722 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1595, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 723 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5877, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 724 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1884, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 725 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.4891, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 726 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.2216, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 727 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.8595, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 728 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3037, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 729 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 730 of 3500\n",
      "INFO:root:single iteration took 1.588 seconds\n",
      "INFO:root:Training is 20 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(128.3596, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 730 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4253, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 731 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.3238, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 732 took 1.569 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.2347, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 733 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4530, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 734 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4630, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 735 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.1611, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 736 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3567, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 737 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 738 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.1624, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 739 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 740 of 3500\n",
      "INFO:root:single iteration took 1.579 seconds\n",
      "INFO:root:Training is 21 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.5153, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 740 took 1.579 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5123, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 741 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1058, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 742 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 743 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0354, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 744 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1465, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 745 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8730, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 746 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3139, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 747 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7895, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 748 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4747, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 749 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 750 of 3500\n",
      "INFO:root:single iteration took 1.594 seconds\n",
      "INFO:root:Training is 21 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.7241, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 750 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.0326, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 751 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5394, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 752 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.1387, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 753 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2493, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 754 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1281, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 755 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1945, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 756 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.5939, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 757 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.8130, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 758 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.7726, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 759 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 760 of 3500\n",
      "INFO:root:single iteration took 1.582 seconds\n",
      "INFO:root:Training is 21 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.7342, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 760 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7269, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 761 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5337, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 762 took 1.576 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3669, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 763 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.0198, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 764 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6799, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 765 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.9564, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 766 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7813, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 767 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6101, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 768 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7763, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 769 took 1.579 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 770 of 3500\n",
      "INFO:root:single iteration took 1.589 seconds\n",
      "INFO:root:Training is 22 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.9689, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 770 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5902, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 771 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.0487, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 772 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.0780, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 773 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.5340, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 774 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.7117, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 775 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3679, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 776 took 1.579 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.5791, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 777 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1783, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 778 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.3090, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 779 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 780 of 3500\n",
      "INFO:root:single iteration took 1.584 seconds\n",
      "INFO:root:Training is 22 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(139.6899, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 780 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1562, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 781 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0096, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 782 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.6901, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 783 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.7832, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 784 took 1.570 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.1231, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 785 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3567, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 786 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.3138, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 787 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8105, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 788 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9666, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 789 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 790 of 3500\n",
      "INFO:root:single iteration took 1.608 seconds\n",
      "INFO:root:Training is 22 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(136.8623, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 790 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.1745, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 791 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9397, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 792 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5627, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 793 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7990, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 794 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5648, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 795 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.9714, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 796 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(146.2765, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 797 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0396, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 798 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 799 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 800 of 3500\n",
      "INFO:root:single iteration took 1.611 seconds\n",
      "INFO:root:Training is 22 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(139.0720, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 800 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.8285, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 801 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6703, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 802 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.0137, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 803 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2494, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 804 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3040, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 805 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.5231, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 806 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.2262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 807 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.0868, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 808 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.4914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 809 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 810 of 3500\n",
      "INFO:root:single iteration took 1.615 seconds\n",
      "INFO:root:Training is 23 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(130.7309, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 810 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3780, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 811 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5503, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 812 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3619, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 813 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.5714, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 814 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3958, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 815 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.9374, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 816 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9853, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 817 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.1599, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 818 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4124, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 819 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 820 of 3500\n",
      "INFO:root:single iteration took 1.602 seconds\n",
      "INFO:root:Training is 23 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.6062, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 820 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.0472, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 821 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7033, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 822 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5073, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 823 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1734, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 824 took 1.570 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9546, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 825 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.2336, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 826 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.2584, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 827 took 1.760 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.1948, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 828 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1907, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 829 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 830 of 3500\n",
      "INFO:root:single iteration took 1.591 seconds\n",
      "INFO:root:Training is 23 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(136.7202, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 830 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7461, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 831 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6228, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 832 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.8518, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 833 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.0881, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 834 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3879, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 835 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2592, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 836 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.3802, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 837 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.6254, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 838 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.1480, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 839 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 840 of 3500\n",
      "INFO:root:single iteration took 1.617 seconds\n",
      "INFO:root:Training is 24 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.4216, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 840 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5892, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 841 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.0203, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 842 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8112, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 843 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 844 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2580, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 845 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.4064, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 846 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.2001, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 847 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.4943, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 848 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.8089, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 849 took 1.579 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 850 of 3500\n",
      "INFO:root:single iteration took 1.577 seconds\n",
      "INFO:root:Training is 24 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(133.0140, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 850 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(107.8810, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 851 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.8488, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 852 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4069, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 853 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8251, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 854 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.6090, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 855 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1125, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 856 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.1113, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 857 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9454, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 858 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0335, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 859 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 860 of 3500\n",
      "INFO:root:single iteration took 1.598 seconds\n",
      "INFO:root:Training is 24 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(142.2548, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 860 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.6162, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 861 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4180, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 862 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.2777, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 863 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9070, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 864 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.1625, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 865 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8605, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 866 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3484, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 867 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4062, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 868 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2413, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 869 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 870 of 3500\n",
      "INFO:root:single iteration took 1.641 seconds\n",
      "INFO:root:Training is 24 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.5639, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 870 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0073, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 871 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8221, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 872 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 873 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6857, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 874 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5398, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 875 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7427, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 876 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8933, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 877 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8177, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 878 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5862, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 879 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 880 of 3500\n",
      "INFO:root:single iteration took 1.588 seconds\n",
      "INFO:root:Training is 25 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.2851, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 880 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2808, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 881 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.9131, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 882 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2602, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 883 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.6518, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 884 took 1.732 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2171, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 885 took 1.573 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5952, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 886 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0073, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 887 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6836, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 888 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0124, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 889 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 890 of 3500\n",
      "INFO:root:single iteration took 1.604 seconds\n",
      "INFO:root:Training is 25 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.0478, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 890 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6264, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 891 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1774, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 892 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8264, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 893 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5824, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 894 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.7491, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 895 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(107.2375, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 896 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7423, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 897 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5901, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 898 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.3229, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 899 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 900 of 3500\n",
      "INFO:root:single iteration took 1.613 seconds\n",
      "INFO:root:Training is 25 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(128.5125, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 900 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9750, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 901 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6036, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 902 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.1335, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 903 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7200, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 904 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.3100, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 905 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.0386, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 906 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0372, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 907 took 1.576 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9295, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 908 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6931, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 909 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 910 of 3500\n",
      "INFO:root:single iteration took 1.602 seconds\n",
      "INFO:root:Training is 26 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.3859, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 910 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8745, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 911 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.4273, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 912 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.5022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 913 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.6985, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 914 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9109, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 915 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0124, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 916 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2801, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 917 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5618, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 918 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7179, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 919 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 920 of 3500\n",
      "INFO:root:single iteration took 1.605 seconds\n",
      "INFO:root:Training is 26 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.6317, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 920 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8284, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 921 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.7215, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 922 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.1945, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 923 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1092, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 924 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2846, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 925 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0083, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 926 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4413, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 927 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7850, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 928 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3104, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 929 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 930 of 3500\n",
      "INFO:root:single iteration took 1.597 seconds\n",
      "INFO:root:Training is 26 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.4930, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 930 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.8667, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 931 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.4366, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 932 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8370, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 933 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 934 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8916, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 935 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8761, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 936 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6190, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 937 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.2891, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 938 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9960, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 939 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 940 of 3500\n",
      "INFO:root:single iteration took 1.638 seconds\n",
      "INFO:root:Training is 26 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(125.0105, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 940 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1007, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 941 took 1.629 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9409, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 942 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9698, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 943 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.2878, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 944 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.0955, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 945 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1930, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 946 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3995, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 947 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1693, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 948 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9490, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 949 took 1.576 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 950 of 3500\n",
      "INFO:root:single iteration took 1.587 seconds\n",
      "INFO:root:Training is 27 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.3638, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 950 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 951 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2839, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 952 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5417, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 953 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4591, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 954 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(149.1133, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 955 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.5874, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 956 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1189, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 957 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6180, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 958 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2789, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 959 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 960 of 3500\n",
      "INFO:root:single iteration took 1.603 seconds\n",
      "INFO:root:Training is 27 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(135.9392, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 960 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6228, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 961 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0418, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 962 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1167, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 963 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.4498, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 964 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6566, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 965 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.5835, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 966 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.7771, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 967 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.4141, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 968 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.3744, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 969 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 970 of 3500\n",
      "INFO:root:single iteration took 1.605 seconds\n",
      "INFO:root:Training is 27 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(122.5624, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 970 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.9138, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 971 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6500, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 972 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2585, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 973 took 1.566 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4320, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 974 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8098, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 975 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4542, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 976 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.3116, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 977 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.4522, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 978 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1676, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 979 took 1.571 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 980 of 3500\n",
      "INFO:root:single iteration took 1.611 seconds\n",
      "INFO:root:Training is 28 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(137.7862, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 980 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7398, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 981 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6191, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 982 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8507, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 983 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5853, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 984 took 1.574 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9678, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 985 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.7310, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 986 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4358, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 987 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.3784, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 988 took 1.628 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.2493, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 989 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 990 of 3500\n",
      "INFO:root:single iteration took 1.581 seconds\n",
      "INFO:root:Training is 28 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.7790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 990 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9166, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 991 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.6292, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 992 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 993 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5108, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 994 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8533, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 995 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4596, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 996 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3445, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 997 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2505, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 998 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7885, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 999 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.4523, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1000 took 1.620 seconds\n",
      "logging train loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1000 of 3500\n",
      "INFO:root:single iteration took 1.620 seconds\n",
      "INFO:root:Training is 28 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9468, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1001 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0281, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1002 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.9637, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1003 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1004 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5795, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1005 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7302, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1006 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6562, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1007 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.7556, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1008 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7511, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1009 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1010 of 3500\n",
      "INFO:root:single iteration took 1.601 seconds\n",
      "INFO:root:Training is 28 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(125.9338, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1010 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3520, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1011 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9193, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1012 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0439, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1013 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9916, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1014 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.9025, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1015 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3038, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1016 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0619, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1017 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8465, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1018 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3257, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1019 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1020 of 3500\n",
      "INFO:root:single iteration took 1.585 seconds\n",
      "INFO:root:Training is 29 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.0170, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1020 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7099, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1021 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.8356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1022 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1023 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3786, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1024 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.4145, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1025 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3220, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1026 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(150.9245, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1027 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0203, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1028 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7185, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1029 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1030 of 3500\n",
      "INFO:root:single iteration took 1.592 seconds\n",
      "INFO:root:Training is 29 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.6762, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1030 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3337, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1031 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8955, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1032 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8362, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1033 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0515, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1034 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.6941, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1035 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.1214, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1036 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1340, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1037 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.5816, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1038 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5776, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1039 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1040 of 3500\n",
      "INFO:root:single iteration took 1.604 seconds\n",
      "INFO:root:Training is 29 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(135.8346, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1040 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1162, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1041 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1042 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0999, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1043 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4067, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1044 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1009, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1045 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9246, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1046 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.5918, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1047 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2711, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1048 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7613, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1049 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1050 of 3500\n",
      "INFO:root:single iteration took 1.592 seconds\n",
      "INFO:root:Training is 30 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.6101, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1050 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2847, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1051 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2826, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1052 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3825, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1053 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.4013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1054 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0869, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1055 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3514, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1056 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5205, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1057 took 1.576 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3706, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1058 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.4330, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1059 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1060 of 3500\n",
      "INFO:root:single iteration took 1.581 seconds\n",
      "INFO:root:Training is 30 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.5936, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1060 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8434, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1061 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.1286, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1062 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.5517, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1063 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5778, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1064 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4180, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1065 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7341, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1066 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0384, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1067 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9613, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1068 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0354, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1069 took 1.574 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1070 of 3500\n",
      "INFO:root:single iteration took 1.615 seconds\n",
      "INFO:root:Training is 30 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(135.9412, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1070 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1378, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1071 took 1.576 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.0152, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1072 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6811, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1073 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9858, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1074 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.8475, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1075 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7669, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1076 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.3282, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1077 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.6005, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1078 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4466, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1079 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1080 of 3500\n",
      "INFO:root:single iteration took 1.607 seconds\n",
      "INFO:root:Training is 30 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.6420, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1080 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9861, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1081 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9743, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1082 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.0826, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1083 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8197, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1084 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8295, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1085 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.4571, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1086 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9984, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1087 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.0626, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1088 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8689, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1089 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1090 of 3500\n",
      "INFO:root:single iteration took 1.578 seconds\n",
      "INFO:root:Training is 31 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.8276, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1090 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3096, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1091 took 1.628 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.5937, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1092 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.3030, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1093 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1799, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1094 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2930, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1095 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5903, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1096 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3399, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1097 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.8109, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1098 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6122, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1099 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1100 of 3500\n",
      "INFO:root:single iteration took 1.604 seconds\n",
      "INFO:root:Training is 31 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(122.9080, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1100 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5246, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1101 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8904, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1102 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5028, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1103 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9482, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1104 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8390, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1105 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2685, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1106 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4931, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1107 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.1421, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1108 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3080, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1109 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1110 of 3500\n",
      "INFO:root:single iteration took 1.578 seconds\n",
      "INFO:root:Training is 31 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.2782, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1110 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.8293, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1111 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6695, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1112 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3595, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1113 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1260, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1114 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7230, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1115 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9037, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1116 took 1.573 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8849, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1117 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8535, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1118 took 1.840 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.8298, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1119 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1120 of 3500\n",
      "INFO:root:single iteration took 1.618 seconds\n",
      "INFO:root:Training is 32 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.1538, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1120 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8781, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1121 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3516, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1122 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5222, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1123 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3324, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1124 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.9773, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1125 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2196, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1126 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6080, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1127 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1366, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1128 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.1836, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1129 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1130 of 3500\n",
      "INFO:root:single iteration took 1.586 seconds\n",
      "INFO:root:Training is 32 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.1162, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1130 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9651, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1131 took 1.571 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3095, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1132 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.5679, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1133 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.6129, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1134 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6328, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1135 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.8840, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1136 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.8015, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1137 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3562, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1138 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2406, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1139 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1140 of 3500\n",
      "INFO:root:single iteration took 1.602 seconds\n",
      "INFO:root:Training is 32 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.3972, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1140 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0639, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1141 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2477, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1142 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.5743, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1143 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5081, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1144 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1145 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8241, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1146 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3311, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1147 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(106.9748, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1148 took 1.566 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.0683, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1149 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1150 of 3500\n",
      "INFO:root:single iteration took 1.608 seconds\n",
      "INFO:root:Training is 32 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(129.4349, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1150 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8764, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1151 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.3863, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1152 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6255, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1153 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9017, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1154 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1746, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1155 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1624, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1156 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.4524, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1157 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1561, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1158 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5947, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1159 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1160 of 3500\n",
      "INFO:root:single iteration took 1.579 seconds\n",
      "INFO:root:Training is 33 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.7124, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1160 took 1.579 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.2194, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1161 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.4391, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1162 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3846, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1163 took 1.579 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5758, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1164 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5152, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1165 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.9956, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1166 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5594, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1167 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8789, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1168 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5889, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1169 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1170 of 3500\n",
      "INFO:root:single iteration took 1.590 seconds\n",
      "INFO:root:Training is 33 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.0564, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1170 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.6203, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1171 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.6443, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1172 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0588, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1173 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.7855, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1174 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9361, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1175 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9637, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1176 took 1.624 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4723, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1177 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8886, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1178 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4895, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1179 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1180 of 3500\n",
      "INFO:root:single iteration took 1.608 seconds\n",
      "INFO:root:Training is 33 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.3156, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1180 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.1055, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1181 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5981, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1182 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4711, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1183 took 1.624 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4459, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1184 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3219, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1185 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7890, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1186 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4209, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1187 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.6585, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1188 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3658, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1189 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1190 of 3500\n",
      "INFO:root:single iteration took 1.597 seconds\n",
      "INFO:root:Training is 34 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.1556, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1190 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8149, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1191 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0259, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1192 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(142.3098, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1193 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5122, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1194 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7811, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1195 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.7928, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1196 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3603, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1197 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.3738, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1198 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.6989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1199 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1200 of 3500\n",
      "INFO:root:single iteration took 1.650 seconds\n",
      "INFO:root:Training is 34 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(156.4102, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1200 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.7356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1201 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3059, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1202 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8249, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1203 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8538, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1204 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3182, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1205 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.2942, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1206 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2352, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1207 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3644, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1208 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.5332, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1209 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1210 of 3500\n",
      "INFO:root:single iteration took 1.596 seconds\n",
      "INFO:root:Training is 34 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(127.0859, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1210 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8040, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1211 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7697, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1212 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1587, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1213 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9932, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1214 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8482, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1215 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.2725, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1216 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1635, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1217 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0778, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1218 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5736, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1219 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1220 of 3500\n",
      "INFO:root:single iteration took 1.677 seconds\n",
      "INFO:root:Training is 34 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(130.7195, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1220 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6724, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1221 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.0216, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1222 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0434, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1223 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.5207, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1224 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8107, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1225 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2802, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1226 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.6657, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1227 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2423, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1228 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.2334, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1229 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1230 of 3500\n",
      "INFO:root:single iteration took 1.615 seconds\n",
      "INFO:root:Training is 35 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.0006, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1230 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1231 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0815, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1232 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1233 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6642, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1234 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1393, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1235 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2427, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1236 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2739, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1237 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7265, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1238 took 1.712 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.4662, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1239 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1240 of 3500\n",
      "INFO:root:single iteration took 1.604 seconds\n",
      "INFO:root:Training is 35 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.5557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1240 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9034, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1241 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1242 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.1943, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1243 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8070, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1244 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3364, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1245 took 1.579 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6716, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1246 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1478, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1247 took 1.573 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.2710, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1248 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8393, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1249 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1250 of 3500\n",
      "INFO:root:single iteration took 1.607 seconds\n",
      "INFO:root:Training is 35 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(131.0051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1250 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5512, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1251 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6122, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1252 took 1.574 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.4305, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1253 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4862, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1254 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8727, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1255 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5831, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1256 took 1.846 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.7634, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1257 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6335, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1258 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3303, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1259 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1260 of 3500\n",
      "INFO:root:single iteration took 1.601 seconds\n",
      "INFO:root:Training is 36 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.0881, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1260 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6645, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1261 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4731, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1262 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8230, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1263 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8968, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1264 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9417, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1265 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1096, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1266 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.5139, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1267 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1174, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1268 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0464, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1269 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1270 of 3500\n",
      "INFO:root:single iteration took 1.741 seconds\n",
      "INFO:root:Training is 36 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.9243, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1270 took 1.741 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4527, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1271 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1272 took 1.729 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4766, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1273 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.4748, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1274 took 1.723 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7081, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1275 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9625, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1276 took 1.738 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2577, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1277 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3418, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1278 took 1.733 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.1368, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1279 took 1.728 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1280 of 3500\n",
      "INFO:root:single iteration took 1.689 seconds\n",
      "INFO:root:Training is 36 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(127.6469, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1280 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3160, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1281 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3346, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1282 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8514, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1283 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.3898, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1284 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.3888, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1285 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5288, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1286 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6742, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1287 took 1.720 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5773, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1288 took 1.886 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5967, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1289 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1290 of 3500\n",
      "INFO:root:single iteration took 1.678 seconds\n",
      "INFO:root:Training is 36 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.9851, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1290 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.3363, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1291 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5476, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1292 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1293 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9857, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1294 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.5615, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1295 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.6000, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1296 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0309, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1297 took 1.709 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.3668, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1298 took 1.769 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3397, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1299 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1300 of 3500\n",
      "INFO:root:single iteration took 1.683 seconds\n",
      "INFO:root:Training is 37 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.6593, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1300 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.3867, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1301 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7728, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1302 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.9260, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1303 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5924, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1304 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.7200, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1305 took 1.742 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(146.6969, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1306 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1307 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8976, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1308 took 1.709 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7368, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1309 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1310 of 3500\n",
      "INFO:root:single iteration took 1.660 seconds\n",
      "INFO:root:Training is 37 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.8090, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1310 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9520, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1311 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9028, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1312 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9066, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1313 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6686, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1314 took 1.628 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6867, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1315 took 1.711 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6252, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1316 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6582, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1317 took 1.724 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9207, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1318 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0828, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1319 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1320 of 3500\n",
      "INFO:root:single iteration took 1.649 seconds\n",
      "INFO:root:Training is 37 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.5040, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1320 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3071, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1321 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6705, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1322 took 1.750 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4354, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1323 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3617, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1324 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8650, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1325 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.6287, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1326 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.7606, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1327 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4236, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1328 took 1.753 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8982, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1329 took 1.737 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1330 of 3500\n",
      "INFO:root:single iteration took 1.697 seconds\n",
      "INFO:root:Training is 38 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.6289, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1330 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.0164, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1331 took 1.723 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8358, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1332 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7937, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1333 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1334 took 1.845 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8502, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1335 took 1.735 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9688, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1336 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0875, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1337 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1303, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1338 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5222, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1339 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1340 of 3500\n",
      "INFO:root:single iteration took 1.696 seconds\n",
      "INFO:root:Training is 38 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(138.0550, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1340 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5804, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1341 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8037, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1342 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1343 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1359, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1344 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.1642, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1345 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0706, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1346 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7643, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1347 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2806, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1348 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9353, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1349 took 1.804 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1350 of 3500\n",
      "INFO:root:single iteration took 1.705 seconds\n",
      "INFO:root:Training is 38 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.8596, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1350 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2666, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1351 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4991, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1352 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2623, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1353 took 1.718 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1637, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1354 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.3914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1355 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0142, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1356 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.7162, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1357 took 1.628 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.9967, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1358 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.1145, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1359 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1360 of 3500\n",
      "INFO:root:single iteration took 1.711 seconds\n",
      "INFO:root:Training is 38 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(135.0747, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1360 took 1.711 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.1048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1361 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2462, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1362 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7534, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1363 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1364 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.0264, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1365 took 1.733 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9748, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1366 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9483, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1367 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8192, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1368 took 1.732 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2530, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1369 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1370 of 3500\n",
      "INFO:root:single iteration took 1.666 seconds\n",
      "INFO:root:Training is 39 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.6429, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1370 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5427, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1371 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1911, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1372 took 1.738 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.9389, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1373 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6428, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1374 took 1.848 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.0742, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1375 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1376 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.8916, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1377 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7727, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1378 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1496, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1379 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1380 of 3500\n",
      "INFO:root:single iteration took 1.684 seconds\n",
      "INFO:root:Training is 39 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.6271, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1380 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7208, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1381 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0006, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1382 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1562, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1383 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1384 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0651, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1385 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6836, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1386 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6577, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1387 took 1.751 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1388 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6448, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1389 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1390 of 3500\n",
      "INFO:root:single iteration took 1.812 seconds\n",
      "INFO:root:Training is 39 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.2030, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1390 took 1.812 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6823, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1391 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6541, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1392 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8533, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1393 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.7131, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1394 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3812, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1395 took 1.572 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3556, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1396 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4512, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1397 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.8209, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1398 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1399 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1400 of 3500\n",
      "INFO:root:single iteration took 1.649 seconds\n",
      "INFO:root:Training is 40 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(131.2847, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1400 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.6668, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1401 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5926, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1402 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.7532, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1403 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.5795, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1404 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4581, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1405 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9189, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1406 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1027, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1407 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4962, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1408 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4236, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1409 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1410 of 3500\n",
      "INFO:root:single iteration took 1.641 seconds\n",
      "INFO:root:Training is 40 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(130.4377, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1410 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0970, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1411 took 1.576 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2276, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1412 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.6901, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1413 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.4012, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1414 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4993, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1415 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6935, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1416 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1661, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1417 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3673, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1418 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1419 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1420 of 3500\n",
      "INFO:root:single iteration took 1.624 seconds\n",
      "INFO:root:Training is 40 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.7645, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1420 took 1.624 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5857, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1421 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.9865, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1422 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8338, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1423 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0916, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1424 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0306, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1425 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4408, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1426 took 1.941 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5493, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1427 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5774, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1428 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6459, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1429 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1430 of 3500\n",
      "INFO:root:single iteration took 1.587 seconds\n",
      "INFO:root:Training is 40 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.4272, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1430 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1431 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.7344, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1432 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1433 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9407, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1434 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3379, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1435 took 1.569 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8863, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1436 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6610, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1437 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3289, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1438 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5156, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1439 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1440 of 3500\n",
      "INFO:root:single iteration took 1.591 seconds\n",
      "INFO:root:Training is 41 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.7697, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1440 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.4759, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1441 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2018, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1442 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4624, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1443 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2568, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1444 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4708, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1445 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.1126, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1446 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0647, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1447 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5464, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1448 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7405, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1449 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1450 of 3500\n",
      "INFO:root:single iteration took 1.595 seconds\n",
      "INFO:root:Training is 41 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(130.9574, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1450 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.7637, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1451 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1567, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1452 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.9502, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1453 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6482, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1454 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0159, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1455 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.9533, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1456 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0059, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1457 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6181, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1458 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8299, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1459 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1460 of 3500\n",
      "INFO:root:single iteration took 1.584 seconds\n",
      "INFO:root:Training is 41 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.6223, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1460 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6455, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1461 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.5014, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1462 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.2428, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1463 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7408, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1464 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9279, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1465 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7649, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1466 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.7542, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1467 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.9933, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1468 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.2578, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1469 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1470 of 3500\n",
      "INFO:root:single iteration took 1.595 seconds\n",
      "INFO:root:Training is 42 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.1137, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1470 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9224, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1471 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8674, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1472 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4529, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1473 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.2734, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1474 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7834, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1475 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3654, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1476 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7990, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1477 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7912, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1478 took 1.576 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.0901, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1479 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1480 of 3500\n",
      "INFO:root:single iteration took 1.593 seconds\n",
      "INFO:root:Training is 42 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.7940, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1480 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2011, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1481 took 1.576 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6855, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1482 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4248, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1483 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8336, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1484 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6495, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1485 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5359, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1486 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9518, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1487 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.0401, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1488 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6617, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1489 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1490 of 3500\n",
      "INFO:root:single iteration took 1.617 seconds\n",
      "INFO:root:Training is 42 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.6699, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1490 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9441, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1491 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8145, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1492 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6646, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1493 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.4507, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1494 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6244, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1495 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9777, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1496 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.1074, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1497 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3839, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1498 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6313, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1499 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3692, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1500 took 1.599 seconds\n",
      "logging train loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1500 of 3500\n",
      "INFO:root:single iteration took 1.599 seconds\n",
      "INFO:root:Training is 42 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1685, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1501 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4385, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1502 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1995, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1503 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0078, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1504 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4260, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1505 took 1.570 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8484, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1506 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2693, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1507 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1508 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.2858, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1509 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1510 of 3500\n",
      "INFO:root:single iteration took 1.625 seconds\n",
      "INFO:root:Training is 43 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.7079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1510 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7117, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1511 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.6400, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1512 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1513 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5463, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1514 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3550, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1515 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1516 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0135, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1517 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0926, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1518 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.5322, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1519 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1520 of 3500\n",
      "INFO:root:single iteration took 1.583 seconds\n",
      "INFO:root:Training is 43 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.1127, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1520 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5379, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1521 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8466, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1522 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1523 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1783, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1524 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.2715, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1525 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2919, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1526 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5699, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1527 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8543, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1528 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8888, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1529 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1530 of 3500\n",
      "INFO:root:single iteration took 1.595 seconds\n",
      "INFO:root:Training is 43 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.8517, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1530 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4899, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1531 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.3282, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1532 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.7796, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1533 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8014, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1534 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1967, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1535 took 1.628 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8535, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1536 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0009, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1537 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0580, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1538 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1139, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1539 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1540 of 3500\n",
      "INFO:root:single iteration took 1.626 seconds\n",
      "INFO:root:Training is 44 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(128.9594, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1540 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9503, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1541 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8823, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1542 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3027, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1543 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6664, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1544 took 1.574 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.5249, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1545 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8071, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1546 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2076, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1547 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1468, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1548 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9298, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1549 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1550 of 3500\n",
      "INFO:root:single iteration took 1.577 seconds\n",
      "INFO:root:Training is 44 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.5162, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1550 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7448, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1551 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3384, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1552 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1590, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1553 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1385, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1554 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7817, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1555 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1750, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1556 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.1426, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1557 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9758, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1558 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.0802, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1559 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1560 of 3500\n",
      "INFO:root:single iteration took 1.588 seconds\n",
      "INFO:root:Training is 44 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.4699, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1560 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.0285, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1561 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.5262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1562 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.0801, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1563 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4325, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1564 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.4516, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1565 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7821, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1566 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7816, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1567 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.2780, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1568 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3705, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1569 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1570 of 3500\n",
      "INFO:root:single iteration took 1.584 seconds\n",
      "INFO:root:Training is 44 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.6563, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1570 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8295, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1571 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6241, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1572 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4185, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1573 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7460, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1574 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8768, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1575 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6868, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1576 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1490, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1577 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.8169, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1578 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.8079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1579 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1580 of 3500\n",
      "INFO:root:single iteration took 1.629 seconds\n",
      "INFO:root:Training is 45 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.0691, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1580 took 1.629 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4529, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1581 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.5731, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1582 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.9140, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1583 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8628, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1584 took 1.754 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4955, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1585 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6755, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1586 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0635, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1587 took 1.733 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8229, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1588 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7514, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1589 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1590 of 3500\n",
      "INFO:root:single iteration took 1.663 seconds\n",
      "INFO:root:Training is 45 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(125.2845, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1590 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2358, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1591 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4331, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1592 took 1.870 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.5390, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1593 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8650, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1594 took 1.740 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2979, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1595 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1931, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1596 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0384, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1597 took 1.724 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1608, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1598 took 1.750 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0985, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1599 took 1.740 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1600 of 3500\n",
      "INFO:root:single iteration took 1.672 seconds\n",
      "INFO:root:Training is 45 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.7834, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1600 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3126, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1601 took 1.712 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8752, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1602 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.7666, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1603 took 1.714 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.1670, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1604 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.8720, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1605 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4007, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1606 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.2355, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1607 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1572, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1608 took 1.772 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.0108, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1609 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1610 of 3500\n",
      "INFO:root:single iteration took 1.711 seconds\n",
      "INFO:root:Training is 46 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.7335, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1610 took 1.711 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0970, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1611 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1031, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1612 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2308, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1613 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0576, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1614 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4420, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1615 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.3332, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1616 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8089, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1617 took 1.714 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1640, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1618 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0726, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1619 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1620 of 3500\n",
      "INFO:root:single iteration took 1.612 seconds\n",
      "INFO:root:Training is 46 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.4158, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1620 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5870, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1621 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0496, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1622 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3955, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1623 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0320, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1624 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9199, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1625 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.7327, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1626 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.7669, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1627 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.9183, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1628 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1700, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1629 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1630 of 3500\n",
      "INFO:root:single iteration took 1.599 seconds\n",
      "INFO:root:Training is 46 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.7952, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1630 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4341, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1631 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.1059, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1632 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.1958, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1633 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3706, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1634 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4830, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1635 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1266, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1636 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4125, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1637 took 1.746 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8338, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1638 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2272, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1639 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1640 of 3500\n",
      "INFO:root:single iteration took 1.597 seconds\n",
      "INFO:root:Training is 46 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.4789, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1640 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.9837, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1641 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4879, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1642 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3565, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1643 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0917, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1644 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2752, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1645 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3679, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1646 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2419, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1647 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6299, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1648 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6817, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1649 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1650 of 3500\n",
      "INFO:root:single iteration took 1.637 seconds\n",
      "INFO:root:Training is 47 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(133.7740, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1650 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.7803, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1651 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1652 took 1.566 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6690, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1653 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1895, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1654 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3624, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1655 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8867, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1656 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5800, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1657 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.9743, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1658 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5545, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1659 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1660 of 3500\n",
      "INFO:root:single iteration took 1.630 seconds\n",
      "INFO:root:Training is 47 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.7971, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1660 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4701, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1661 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2668, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1662 took 1.760 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8088, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1663 took 1.731 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0547, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1664 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0412, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1665 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9604, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1666 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6424, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1667 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9380, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1668 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7750, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1669 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1670 of 3500\n",
      "INFO:root:single iteration took 1.566 seconds\n",
      "INFO:root:Training is 47 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.3071, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1670 took 1.566 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2459, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1671 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3523, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1672 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1670, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1673 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0971, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1674 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3917, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1675 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0997, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1676 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.5772, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1677 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8277, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1678 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7581, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1679 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1680 of 3500\n",
      "INFO:root:single iteration took 1.639 seconds\n",
      "INFO:root:Training is 48 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.1736, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1680 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.7151, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1681 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2288, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1682 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9553, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1683 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6912, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1684 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.9836, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1685 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0895, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1686 took 1.815 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3628, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1687 took 1.782 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6208, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1688 took 1.816 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5636, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1689 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1690 of 3500\n",
      "INFO:root:single iteration took 1.646 seconds\n",
      "INFO:root:Training is 48 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.4324, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1690 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0866, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1691 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3607, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1692 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9195, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1693 took 1.744 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.3190, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1694 took 1.753 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.3227, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1695 took 1.741 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.5119, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1696 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2867, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1697 took 1.739 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.6376, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1698 took 1.800 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.6120, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1699 took 1.734 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1700 of 3500\n",
      "INFO:root:single iteration took 1.810 seconds\n",
      "INFO:root:Training is 48 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.6227, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1700 took 1.810 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2638, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1701 took 1.730 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0908, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1702 took 1.739 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.2941, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1703 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0362, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1704 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8832, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1705 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6448, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1706 took 1.746 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2354, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1707 took 1.721 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2868, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1708 took 1.740 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4594, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1709 took 1.736 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4679, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1710 took 1.801 seconds\n",
      "logging train loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1710 of 3500\n",
      "INFO:root:single iteration took 1.801 seconds\n",
      "INFO:root:Training is 48 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2642, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1711 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8457, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1712 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9522, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1713 took 1.774 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9606, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1714 took 1.726 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9518, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1715 took 1.798 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1840, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1716 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.0758, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1717 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.4811, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1718 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.3073, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1719 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1720 of 3500\n",
      "INFO:root:single iteration took 1.705 seconds\n",
      "INFO:root:Training is 49 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.8098, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1720 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3247, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1721 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.1748, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1722 took 1.727 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5704, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1723 took 1.725 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1724 took 1.728 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1725 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0455, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1726 took 1.717 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.9501, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1727 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7393, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1728 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5547, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1729 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1730 of 3500\n",
      "INFO:root:single iteration took 1.714 seconds\n",
      "INFO:root:Training is 49 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(128.5042, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1730 took 1.714 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0534, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1731 took 1.719 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.0626, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1732 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.4441, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1733 took 1.739 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0840, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1734 took 1.785 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1735 took 1.746 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4210, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1736 took 1.762 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1737 took 1.760 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6653, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1738 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5955, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1739 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1740 of 3500\n",
      "INFO:root:single iteration took 1.712 seconds\n",
      "INFO:root:Training is 49 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.0832, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1740 took 1.712 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.3034, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1741 took 1.764 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.2936, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1742 took 1.747 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7595, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1743 took 1.751 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.3427, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1744 took 1.747 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6236, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1745 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0482, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1746 took 1.939 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9507, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1747 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4532, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1748 took 1.767 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6859, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1749 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1750 of 3500\n",
      "INFO:root:single iteration took 1.680 seconds\n",
      "INFO:root:Training is 50 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.2556, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1750 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1751 took 1.722 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9095, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1752 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.4105, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1753 took 1.750 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7227, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1754 took 1.839 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1281, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1755 took 1.815 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2508, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1756 took 1.745 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.1516, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1757 took 1.736 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6389, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1758 took 1.735 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7160, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1759 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1760 of 3500\n",
      "INFO:root:single iteration took 1.601 seconds\n",
      "INFO:root:Training is 50 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.6134, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1760 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5676, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1761 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7409, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1762 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.0259, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1763 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.1024, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1764 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.7662, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1765 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7860, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1766 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.9697, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1767 took 1.728 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(476.2623, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1768 took 1.739 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6365, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1769 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1770 of 3500\n",
      "INFO:root:single iteration took 1.627 seconds\n",
      "INFO:root:Training is 50 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.1079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1770 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0390, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1771 took 1.711 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6410, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1772 took 1.738 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(143.3464, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1773 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1799, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1774 took 1.717 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.4807, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1775 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.4006, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1776 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5009, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1777 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.8478, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1778 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6585, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1779 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1780 of 3500\n",
      "INFO:root:single iteration took 1.698 seconds\n",
      "INFO:root:Training is 50 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.3841, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1780 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5112, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1781 took 1.628 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5698, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1782 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1020, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1783 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5528, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1784 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1785 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2156, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1786 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1787 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7889, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1788 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3138, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1789 took 1.723 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1790 of 3500\n",
      "INFO:root:single iteration took 1.747 seconds\n",
      "INFO:root:Training is 51 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.4230, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1790 took 1.747 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1717, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1791 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6943, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1792 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0040, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1793 took 1.735 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8314, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1794 took 1.752 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5378, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1795 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1154, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1796 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4408, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1797 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(154.4424, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1798 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(145.1265, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1799 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1800 of 3500\n",
      "INFO:root:single iteration took 1.656 seconds\n",
      "INFO:root:Training is 51 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.9489, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1800 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8494, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1801 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.6705, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1802 took 1.798 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.7678, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1803 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0293, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1804 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9231, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1805 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6255, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1806 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1687, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1807 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0566, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1808 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8903, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1809 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1810 of 3500\n",
      "INFO:root:single iteration took 1.596 seconds\n",
      "INFO:root:Training is 51 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.8936, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1810 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5976, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1811 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0692, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1812 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8565, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1813 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1736, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1814 took 1.574 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5951, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1815 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2891, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1816 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8514, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1817 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6927, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1818 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9716, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1819 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1820 of 3500\n",
      "INFO:root:single iteration took 1.642 seconds\n",
      "INFO:root:Training is 52 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.7464, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1820 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.6414, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1821 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4430, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1822 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.4288, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1823 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0818, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1824 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6460, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1825 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.9914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1826 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7589, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1827 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2417, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1828 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.6359, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1829 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1830 of 3500\n",
      "INFO:root:single iteration took 1.621 seconds\n",
      "INFO:root:Training is 52 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.6645, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1830 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7759, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1831 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0256, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1832 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1444, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1833 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3607, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1834 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3550, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1835 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.3882, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1836 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4810, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1837 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3130, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1838 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9894, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1839 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1840 of 3500\n",
      "INFO:root:single iteration took 1.592 seconds\n",
      "INFO:root:Training is 52 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.3780, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1840 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3841, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1841 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.5354, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1842 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8310, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1843 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1853, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1844 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1243, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1845 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4854, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1846 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3810, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1847 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1965, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1848 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2958, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1849 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1850 of 3500\n",
      "INFO:root:single iteration took 1.614 seconds\n",
      "INFO:root:Training is 52 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(131.8276, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1850 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.2089, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1851 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8436, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1852 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6118, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1853 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6313, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1854 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0580, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1855 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6570, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1856 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9704, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1857 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4785, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1858 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9010, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1859 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1860 of 3500\n",
      "INFO:root:single iteration took 1.631 seconds\n",
      "INFO:root:Training is 53 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.9798, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1860 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.7871, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1861 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.4897, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1862 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.5570, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1863 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0512, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1864 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.6036, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1865 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6235, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1866 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3521, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1867 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6176, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1868 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5112, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1869 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1870 of 3500\n",
      "INFO:root:single iteration took 1.653 seconds\n",
      "INFO:root:Training is 53 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(128.4548, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1870 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5460, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1871 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8134, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1872 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0015, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1873 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9864, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1874 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1295, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1875 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2822, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1876 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8535, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1877 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(143.0126, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1878 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3600, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1879 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1880 of 3500\n",
      "INFO:root:single iteration took 1.626 seconds\n",
      "INFO:root:Training is 53 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.4714, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1880 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7672, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1881 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5382, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1882 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1883 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.5068, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1884 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6544, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1885 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.0508, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1886 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3177, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1887 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0854, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1888 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.2574, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1889 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1890 of 3500\n",
      "INFO:root:single iteration took 1.668 seconds\n",
      "INFO:root:Training is 54 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.8366, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1890 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6035, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1891 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1212, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1892 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6155, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1893 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.2522, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1894 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0835, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1895 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4045, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1896 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9661, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1897 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4166, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1898 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2531, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1899 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1900 of 3500\n",
      "INFO:root:single iteration took 1.589 seconds\n",
      "INFO:root:Training is 54 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.7051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1900 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6463, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1901 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9547, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1902 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2475, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1903 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9091, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1904 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8490, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1905 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1083, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1906 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9516, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1907 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(171.5319, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1908 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0375, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1909 took 1.574 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1910 of 3500\n",
      "INFO:root:single iteration took 1.582 seconds\n",
      "INFO:root:Training is 54 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.4191, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1910 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.2483, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1911 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.3192, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1912 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6934, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1913 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.2019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1914 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0606, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1915 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6328, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1916 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5784, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1917 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9627, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1918 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9736, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1919 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1920 of 3500\n",
      "INFO:root:single iteration took 1.603 seconds\n",
      "INFO:root:Training is 54 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.7943, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1920 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2142, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1921 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6680, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1922 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4342, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1923 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1289, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1924 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.1768, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1925 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.8080, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1926 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.7586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1927 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4207, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1928 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4334, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1929 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1930 of 3500\n",
      "INFO:root:single iteration took 1.610 seconds\n",
      "INFO:root:Training is 55 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.3005, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1930 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5688, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1931 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1932 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8175, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1933 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.2356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1934 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0158, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1935 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9597, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1936 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1937 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.7761, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1938 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5929, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1939 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1940 of 3500\n",
      "INFO:root:single iteration took 1.580 seconds\n",
      "INFO:root:Training is 55 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.0763, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1940 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4887, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1941 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5616, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1942 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6381, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1943 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9491, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1944 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1218, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1945 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7781, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1946 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3406, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1947 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6014, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1948 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4684, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1949 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1950 of 3500\n",
      "INFO:root:single iteration took 1.655 seconds\n",
      "INFO:root:Training is 55 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.3922, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1950 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8659, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1951 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0513, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1952 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1858, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1953 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1515, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1954 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4408, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1955 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4238, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1956 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5708, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1957 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9478, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1958 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8059, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1959 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1960 of 3500\n",
      "INFO:root:single iteration took 1.591 seconds\n",
      "INFO:root:Training is 56 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.2986, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1960 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7247, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1961 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(106.4336, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1962 took 1.574 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0451, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1963 took 1.629 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8806, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1964 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2091, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1965 took 1.833 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.0789, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1966 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9043, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1967 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0679, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1968 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.2262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1969 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1970 of 3500\n",
      "INFO:root:single iteration took 1.639 seconds\n",
      "INFO:root:Training is 56 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.7148, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1970 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5610, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1971 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0190, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1972 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1077, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1973 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1765, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1974 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3794, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1975 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3741, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1976 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3430, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1977 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.5268, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1978 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8546, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1979 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1980 of 3500\n",
      "INFO:root:single iteration took 1.604 seconds\n",
      "INFO:root:Training is 56 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.7606, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1980 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6719, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1981 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9866, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1982 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(109.7455, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1983 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7745, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1984 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8128, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1985 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7278, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1986 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5830, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1987 took 1.618 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8066, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1988 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3561, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1989 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 1990 of 3500\n",
      "INFO:root:single iteration took 1.615 seconds\n",
      "INFO:root:Training is 56 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(127.3565, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1990 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4679, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1991 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.6879, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1992 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0756, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1993 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4776, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1994 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1821, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1995 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8044, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1996 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.4705, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1997 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.1845, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1998 took 1.598 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8339, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 1999 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5547, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2000 took 1.602 seconds\n",
      "logging train loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2000 of 3500\n",
      "INFO:root:single iteration took 1.602 seconds\n",
      "INFO:root:Training is 57 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0232, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2001 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4330, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2002 took 1.624 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8710, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2003 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3432, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2004 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4376, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2005 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2006 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6667, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2007 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3222, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2008 took 1.606 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2874, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2009 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2010 of 3500\n",
      "INFO:root:single iteration took 1.624 seconds\n",
      "INFO:root:Training is 57 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(131.7087, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2010 took 1.624 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0984, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2011 took 1.628 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2012 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1742, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2013 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8038, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2014 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6529, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2015 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0901, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2016 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7344, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2017 took 1.580 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.0634, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2018 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0894, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2019 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2020 of 3500\n",
      "INFO:root:single iteration took 1.584 seconds\n",
      "INFO:root:Training is 57 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(111.9785, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2020 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0793, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2021 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7849, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2022 took 1.603 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5265, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2023 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(139.4919, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2024 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.7648, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2025 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6814, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2026 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.7878, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2027 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2582, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2028 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3062, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2029 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2030 of 3500\n",
      "INFO:root:single iteration took 1.626 seconds\n",
      "INFO:root:Training is 58 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.7639, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2030 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7509, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2031 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.1446, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2032 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.4511, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2033 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2460, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2034 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0923, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2035 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0248, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2036 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2257, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2037 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8522, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2038 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.3537, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2039 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2040 of 3500\n",
      "INFO:root:single iteration took 1.625 seconds\n",
      "INFO:root:Training is 58 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(122.5279, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2040 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.0147, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2041 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0944, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2042 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2043 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.2676, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2044 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3772, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2045 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.7073, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2046 took 1.632 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8882, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2047 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9142, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2048 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1006, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2049 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2050 of 3500\n",
      "INFO:root:single iteration took 1.608 seconds\n",
      "INFO:root:Training is 58 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.3290, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2050 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4786, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2051 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6780, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2052 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1643, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2053 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.3776, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2054 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1818, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2055 took 1.591 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8531, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2056 took 1.600 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6015, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2057 took 1.592 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2501, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2058 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2360, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2059 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2060 of 3500\n",
      "INFO:root:single iteration took 1.590 seconds\n",
      "INFO:root:Training is 58 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(127.6843, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2060 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3996, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2061 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.1708, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2062 took 1.611 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8000, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2063 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0223, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2064 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1496, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2065 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5771, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2066 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.3461, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2067 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9522, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2068 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2827, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2069 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2070 of 3500\n",
      "INFO:root:single iteration took 1.594 seconds\n",
      "INFO:root:Training is 59 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.9430, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2070 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0350, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2071 took 1.608 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2072 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7450, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2073 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5457, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2074 took 1.588 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5083, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2075 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5230, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2076 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3167, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2077 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2078 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(134.9761, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2079 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2080 of 3500\n",
      "INFO:root:single iteration took 1.578 seconds\n",
      "INFO:root:Training is 59 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.9501, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2080 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2081 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3719, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2082 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.1357, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2083 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7526, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2084 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7813, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2085 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9473, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2086 took 1.586 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9988, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2087 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8939, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2088 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7291, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2089 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2090 of 3500\n",
      "INFO:root:single iteration took 1.803 seconds\n",
      "INFO:root:Training is 59 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.2461, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2090 took 1.803 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8130, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2091 took 1.885 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1698, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2092 took 1.607 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1953, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2093 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4758, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2094 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2384, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2095 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9723, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2096 took 1.584 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7121, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2097 took 1.610 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2761, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2098 took 1.579 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.6736, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2099 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2100 of 3500\n",
      "INFO:root:single iteration took 1.578 seconds\n",
      "INFO:root:Training is 60 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.0153, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2100 took 1.578 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0115, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2101 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.4431, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2102 took 1.624 seconds\n",
      "logging train loss\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7095, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2103 took 1.609 seconds\n",
      "logging train loss\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.2646, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2104 took 1.591 seconds\n",
      "logging train loss\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1182, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2105 took 1.603 seconds\n",
      "logging train loss\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8021, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2106 took 1.601 seconds\n",
      "logging train loss\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.4123, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2107 took 1.618 seconds\n",
      "logging train loss\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8045, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2108 took 1.611 seconds\n",
      "logging train loss\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.7098, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2109 took 1.626 seconds\n",
      "logging train loss\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2110 of 3500\n",
      "INFO:root:single iteration took 1.629 seconds\n",
      "INFO:root:Training is 60 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(134.5211, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2110 took 1.629 seconds\n",
      "logging train loss\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0951, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2111 took 1.629 seconds\n",
      "logging train loss\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1350, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2112 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4371, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2113 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5595, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2114 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7936, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2115 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.4623, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2116 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.8761, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2117 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.5146, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2118 took 1.612 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6412, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2119 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2120 of 3500\n",
      "INFO:root:single iteration took 1.599 seconds\n",
      "INFO:root:Training is 60 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(125.9018, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2120 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2121 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1895, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2122 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7097, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2123 took 1.597 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2517, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2124 took 1.585 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2125 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.7139, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2126 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5881, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2127 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.0157, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2128 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5777, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2129 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2130 of 3500\n",
      "INFO:root:single iteration took 1.583 seconds\n",
      "INFO:root:Training is 60 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.7667, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2130 took 1.583 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6400, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2131 took 1.577 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2730, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2132 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0768, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2133 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7691, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2134 took 1.590 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5334, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2135 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5688, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2136 took 1.587 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6697, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2137 took 1.581 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.3012, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2138 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.1873, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2139 took 1.601 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2140 of 3500\n",
      "INFO:root:single iteration took 1.647 seconds\n",
      "INFO:root:Training is 61 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.6116, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2140 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.9313, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2141 took 1.620 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.6792, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2142 took 1.613 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.7834, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2143 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.5977, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2144 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6437, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2145 took 1.714 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2758, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2146 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9575, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2147 took 1.617 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9528, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2148 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.0273, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2149 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2150 of 3500\n",
      "INFO:root:single iteration took 1.593 seconds\n",
      "INFO:root:Training is 61 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.1788, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2150 took 1.593 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8737, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2151 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.0714, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2152 took 1.709 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.6885, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2153 took 1.615 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9507, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2154 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4747, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2155 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9036, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2156 took 1.595 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.7233, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2157 took 1.621 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1345, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2158 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1219, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2159 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2160 of 3500\n",
      "INFO:root:single iteration took 1.715 seconds\n",
      "INFO:root:Training is 61 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(122.9563, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2160 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4235, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2161 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4184, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2162 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6858, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2163 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3002, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2164 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4116, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2165 took 1.802 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.0647, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2166 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0639, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2167 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7746, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2168 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4772, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2169 took 1.636 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2170 of 3500\n",
      "INFO:root:single iteration took 1.604 seconds\n",
      "INFO:root:Training is 62 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.3722, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2170 took 1.604 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2285, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2171 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.4573, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2172 took 1.629 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6834, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2173 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.8064, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2174 took 1.589 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.5493, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2175 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2942, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2176 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6888, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2177 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4495, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2178 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3600, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2179 took 1.636 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2180 of 3500\n",
      "INFO:root:single iteration took 1.687 seconds\n",
      "INFO:root:Training is 62 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.3751, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2180 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5180, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2181 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9919, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2182 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5623, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2183 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9644, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2184 took 1.596 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8786, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2185 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.3138, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2186 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2172, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2187 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.7324, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2188 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.4448, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2189 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2190 of 3500\n",
      "INFO:root:single iteration took 1.667 seconds\n",
      "INFO:root:Training is 62 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.7676, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2190 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6535, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2191 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(109.6107, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2192 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4000, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2193 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5021, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2194 took 1.717 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(109.1837, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2195 took 1.616 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5643, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2196 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7917, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2197 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2638, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2198 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3864, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2199 took 1.720 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2200 of 3500\n",
      "INFO:root:single iteration took 1.685 seconds\n",
      "INFO:root:Training is 62 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(139.5672, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2200 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.8868, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2201 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.0866, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2202 took 1.602 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(138.2112, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2203 took 1.609 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7008, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2204 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7111, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2205 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8537, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2206 took 1.636 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6223, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2207 took 1.791 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2717, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2208 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.9074, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2209 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2210 of 3500\n",
      "INFO:root:single iteration took 1.627 seconds\n",
      "INFO:root:Training is 63 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.3430, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2210 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9332, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2211 took 1.726 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8113, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2212 took 1.748 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5997, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2213 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8633, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2214 took 1.599 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.9530, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2215 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8700, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2216 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5947, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2217 took 1.636 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2218 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2219 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2220 of 3500\n",
      "INFO:root:single iteration took 1.638 seconds\n",
      "INFO:root:Training is 63 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.0961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2220 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.4700, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2221 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4409, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2222 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.4850, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2223 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4290, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2224 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0589, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2225 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9755, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2226 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2803, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2227 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5249, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2228 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3018, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2229 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2230 of 3500\n",
      "INFO:root:single iteration took 1.614 seconds\n",
      "INFO:root:Training is 63 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.2657, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2230 took 1.614 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8494, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2231 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.0029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2232 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2233 took 1.749 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8103, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2234 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7791, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2235 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2236 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1963, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2237 took 1.605 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9067, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2238 took 1.725 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.6887, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2239 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2240 of 3500\n",
      "INFO:root:single iteration took 1.663 seconds\n",
      "INFO:root:Training is 64 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.4459, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2240 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.1857, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2241 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.7427, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2242 took 1.594 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5635, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2243 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0397, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2244 took 1.575 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.0963, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2245 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3193, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2246 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0588, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2247 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1300, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2248 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9715, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2249 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2250 of 3500\n",
      "INFO:root:single iteration took 1.677 seconds\n",
      "INFO:root:Training is 64 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.1717, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2250 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.8117, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2251 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4575, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2252 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9850, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2253 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8957, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2254 took 1.712 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7171, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2255 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1836, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2256 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9251, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2257 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.6181, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2258 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7837, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2259 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2260 of 3500\n",
      "INFO:root:single iteration took 1.701 seconds\n",
      "INFO:root:Training is 64 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(129.5193, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2260 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3897, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2261 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.7448, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2262 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(109.2296, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2263 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.4635, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2264 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9782, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2265 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8570, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2266 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7254, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2267 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.3628, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2268 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7511, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2269 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2270 of 3500\n",
      "INFO:root:single iteration took 1.677 seconds\n",
      "INFO:root:Training is 64 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(110.8795, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2270 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0637, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2271 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2859, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2272 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0697, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2273 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9505, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2274 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9653, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2275 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5843, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2276 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0770, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2277 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(109.6521, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2278 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4565, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2279 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2280 of 3500\n",
      "INFO:root:single iteration took 1.658 seconds\n",
      "INFO:root:Training is 65 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.2505, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2280 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2194, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2281 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4378, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2282 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7644, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2283 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.1375, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2284 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2794, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2285 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2286 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3495, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2287 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2871, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2288 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2289 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2290 of 3500\n",
      "INFO:root:single iteration took 1.669 seconds\n",
      "INFO:root:Training is 65 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(111.2996, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2290 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7111, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2291 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9920, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2292 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0291, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2293 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7648, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2294 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8187, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2295 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5466, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2296 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9743, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2297 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.1315, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2298 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4460, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2299 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2300 of 3500\n",
      "INFO:root:single iteration took 1.685 seconds\n",
      "INFO:root:Training is 65 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.7269, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2300 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4155, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2301 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5879, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2302 took 1.767 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.2474, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2303 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.5936, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2304 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0906, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2305 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.5307, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2306 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5452, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2307 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9802, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2308 took 1.722 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.8244, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2309 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2310 of 3500\n",
      "INFO:root:single iteration took 1.711 seconds\n",
      "INFO:root:Training is 66 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.3251, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2310 took 1.711 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4719, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2311 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2455, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2312 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5383, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2313 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3193, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2314 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8212, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2315 took 1.729 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3317, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2316 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2483, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2317 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2328, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2318 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2493, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2319 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2320 of 3500\n",
      "INFO:root:single iteration took 1.657 seconds\n",
      "INFO:root:Training is 66 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(111.3677, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2320 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9459, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2321 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.0157, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2322 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.4100, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2323 took 1.815 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.9867, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2324 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6566, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2325 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2326 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0568, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2327 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2328 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1357, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2329 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2330 of 3500\n",
      "INFO:root:single iteration took 1.641 seconds\n",
      "INFO:root:Training is 66 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.1730, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2330 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.4940, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2331 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8828, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2332 took 1.742 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8498, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2333 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8912, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2334 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2628, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2335 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3455, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2336 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8287, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2337 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.4003, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2338 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9412, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2339 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2340 of 3500\n",
      "INFO:root:single iteration took 1.673 seconds\n",
      "INFO:root:Training is 66 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.4739, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2340 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2341 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4724, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2342 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0030, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2343 took 1.721 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.6931, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2344 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4206, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2345 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9497, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2346 took 1.636 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.1137, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2347 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2457, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2348 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(109.9935, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2349 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2350 of 3500\n",
      "INFO:root:single iteration took 1.649 seconds\n",
      "INFO:root:Training is 67 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(122.6985, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2350 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(141.1946, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2351 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0425, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2352 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0966, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2353 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7085, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2354 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8071, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2355 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2356 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8406, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2357 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9686, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2358 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1400, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2359 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2360 of 3500\n",
      "INFO:root:single iteration took 1.647 seconds\n",
      "INFO:root:Training is 67 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.1779, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2360 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3818, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2361 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5894, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2362 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9562, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2363 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.1789, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2364 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6306, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2365 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.6013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2366 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3379, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2367 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4996, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2368 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0227, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2369 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2370 of 3500\n",
      "INFO:root:single iteration took 1.673 seconds\n",
      "INFO:root:Training is 67 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.8767, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2370 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5836, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2371 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.8962, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2372 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3561, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2373 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0436, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2374 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6897, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2375 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4292, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2376 took 1.628 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7921, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2377 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.6393, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2378 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.7747, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2379 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2380 of 3500\n",
      "INFO:root:single iteration took 1.676 seconds\n",
      "INFO:root:Training is 68 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.2283, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2380 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.9305, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2381 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8651, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2382 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9933, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2383 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6031, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2384 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6299, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2385 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0529, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2386 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2387 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2532, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2388 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7819, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2389 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2390 of 3500\n",
      "INFO:root:single iteration took 1.664 seconds\n",
      "INFO:root:Training is 68 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.7989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2390 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.1381, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2391 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8214, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2392 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.0339, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2393 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7720, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2394 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4889, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2395 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9256, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2396 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5780, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2397 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2398 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2399 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2400 of 3500\n",
      "INFO:root:single iteration took 1.678 seconds\n",
      "INFO:root:Training is 68 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(128.6698, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2400 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2401 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.1545, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2402 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0674, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2403 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5852, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2404 took 1.773 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3027, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2405 took 1.806 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9911, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2406 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.9358, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2407 took 1.735 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5110, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2408 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(137.3157, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2409 took 2.124 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2410 of 3500\n",
      "INFO:root:single iteration took 1.679 seconds\n",
      "INFO:root:Training is 68 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.9164, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2410 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.7808, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2411 took 1.769 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5011, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2412 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7909, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2413 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5825, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2414 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8411, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2415 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9856, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2416 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2851, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2417 took 1.807 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1296, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2418 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2409, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2419 took 1.889 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2420 of 3500\n",
      "INFO:root:single iteration took 1.682 seconds\n",
      "INFO:root:Training is 69 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(127.6591, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2420 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6655, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2421 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.5368, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2422 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9912, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2423 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6438, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2424 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7924, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2425 took 1.755 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4634, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2426 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9902, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2427 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6417, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2428 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4517, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2429 took 1.727 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2430 of 3500\n",
      "INFO:root:single iteration took 1.672 seconds\n",
      "INFO:root:Training is 69 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(132.0831, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2430 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9111, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2431 took 1.718 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2306, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2432 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7474, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2433 took 1.709 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2884, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2434 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7390, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2435 took 1.736 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.2843, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2436 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1944, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2437 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7948, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2438 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3709, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2439 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2440 of 3500\n",
      "INFO:root:single iteration took 1.665 seconds\n",
      "INFO:root:Training is 69 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.5539, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2440 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1335, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2441 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9351, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2442 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5778, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2443 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9617, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2444 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2497, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2445 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5237, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2446 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.7572, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2447 took 1.736 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1391, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2448 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9590, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2449 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2450 of 3500\n",
      "INFO:root:single iteration took 1.634 seconds\n",
      "INFO:root:Training is 70 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.1646, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2450 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6421, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2451 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.5798, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2452 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0813, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2453 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6582, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2454 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7714, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2455 took 1.709 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7435, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2456 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.3037, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2457 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5547, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2458 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0481, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2459 took 1.622 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2460 of 3500\n",
      "INFO:root:single iteration took 1.769 seconds\n",
      "INFO:root:Training is 70 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.4592, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2460 took 1.769 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1797, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2461 took 1.726 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4200, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2462 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3972, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2463 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0407, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2464 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4001, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2465 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2466 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.1904, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2467 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6828, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2468 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6683, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2469 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2470 of 3500\n",
      "INFO:root:single iteration took 1.677 seconds\n",
      "INFO:root:Training is 70 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(132.4193, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2470 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6696, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2471 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.3874, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2472 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.3965, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2473 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1779, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2474 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2180, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2475 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5987, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2476 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.8020, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2477 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8500, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2478 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.0694, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2479 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2480 of 3500\n",
      "INFO:root:single iteration took 1.691 seconds\n",
      "INFO:root:Training is 70 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.6354, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2480 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5565, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2481 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6117, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2482 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3059, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2483 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0901, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2484 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.8379, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2485 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.0245, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2486 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3349, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2487 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6160, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2488 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9939, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2489 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2490 of 3500\n",
      "INFO:root:single iteration took 1.712 seconds\n",
      "INFO:root:Training is 71 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.8054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2490 took 1.712 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3201, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2491 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8010, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2492 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8661, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2493 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1460, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2494 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8481, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2495 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5321, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2496 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5531, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2497 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2498 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1818, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2499 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2500 took 1.701 seconds\n",
      "logging train loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2500 of 3500\n",
      "INFO:root:single iteration took 1.701 seconds\n",
      "INFO:root:Training is 71 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3638, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2501 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9163, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2502 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.1758, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2503 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8261, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2504 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7724, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2505 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3965, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2506 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5726, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2507 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5542, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2508 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.5782, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2509 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2510 of 3500\n",
      "INFO:root:single iteration took 1.695 seconds\n",
      "INFO:root:Training is 71 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.1325, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2510 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9598, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2511 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2582, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2512 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1312, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2513 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4827, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2514 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.9099, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2515 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7509, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2516 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0165, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2517 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.0198, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2518 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4033, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2519 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2520 of 3500\n",
      "INFO:root:single iteration took 1.661 seconds\n",
      "INFO:root:Training is 72 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.5286, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2520 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.8619, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2521 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1433, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2522 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2975, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2523 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5818, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2524 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.6082, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2525 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1695, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2526 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.9243, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2527 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0274, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2528 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0284, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2529 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2530 of 3500\n",
      "INFO:root:single iteration took 1.649 seconds\n",
      "INFO:root:Training is 72 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.6942, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2530 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(104.8305, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2531 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5840, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2532 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2647, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2533 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2323, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2534 took 1.723 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5636, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2535 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9391, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2536 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2537 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1177, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2538 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.0607, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2539 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2540 of 3500\n",
      "INFO:root:single iteration took 1.619 seconds\n",
      "INFO:root:Training is 72 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.9509, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2540 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5369, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2541 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.3969, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2542 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0570, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2543 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1297, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2544 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3865, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2545 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8979, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2546 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1535, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2547 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5700, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2548 took 1.722 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3933, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2549 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2550 of 3500\n",
      "INFO:root:single iteration took 1.670 seconds\n",
      "INFO:root:Training is 72 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.2084, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2550 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6712, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2551 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4809, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2552 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0734, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2553 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7682, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2554 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5991, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2555 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1280, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2556 took 1.726 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4284, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2557 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8008, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2558 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2858, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2559 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2560 of 3500\n",
      "INFO:root:single iteration took 1.655 seconds\n",
      "INFO:root:Training is 73 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(133.7309, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2560 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9339, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2561 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6025, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2562 took 1.782 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6351, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2563 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8657, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2564 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3841, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2565 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2185, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2566 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7631, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2567 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1994, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2568 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0961, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2569 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2570 of 3500\n",
      "INFO:root:single iteration took 1.655 seconds\n",
      "INFO:root:Training is 73 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.0484, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2570 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.9858, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2571 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3382, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2572 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.3905, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2573 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6348, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2574 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2519, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2575 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4750, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2576 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5650, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2577 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5271, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2578 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0793, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2579 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2580 of 3500\n",
      "INFO:root:single iteration took 1.701 seconds\n",
      "INFO:root:Training is 73 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.5146, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2580 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7361, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2581 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5828, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2582 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7945, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2583 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2142, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2584 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1087, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2585 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9266, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2586 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2554, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2587 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1089, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2588 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4522, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2589 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2590 of 3500\n",
      "INFO:root:single iteration took 1.896 seconds\n",
      "INFO:root:Training is 74 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.5663, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2590 took 1.896 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3539, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2591 took 1.793 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3928, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2592 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5983, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2593 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.4348, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2594 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.4138, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2595 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3811, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2596 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2912, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2597 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6517, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2598 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0333, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2599 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2600 of 3500\n",
      "INFO:root:single iteration took 1.694 seconds\n",
      "INFO:root:Training is 74 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(127.7416, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2600 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7865, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2601 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8439, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2602 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8824, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2603 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8157, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2604 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8153, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2605 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6437, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2606 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.4427, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2607 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.0255, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2608 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6179, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2609 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2610 of 3500\n",
      "INFO:root:single iteration took 1.733 seconds\n",
      "INFO:root:Training is 74 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.6576, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2610 took 1.733 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7865, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2611 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0210, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2612 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7074, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2613 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8977, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2614 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2276, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2615 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2030, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2616 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1223, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2617 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0784, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2618 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3322, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2619 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2620 of 3500\n",
      "INFO:root:single iteration took 1.643 seconds\n",
      "INFO:root:Training is 74 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.5488, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2620 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9011, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2621 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4887, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2622 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.7502, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2623 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2624 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4129, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2625 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7941, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2626 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4125, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2627 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4405, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2628 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7131, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2629 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2630 of 3500\n",
      "INFO:root:single iteration took 1.689 seconds\n",
      "INFO:root:Training is 75 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.1180, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2630 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7332, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2631 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2632 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.4489, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2633 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0753, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2634 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9923, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2635 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6609, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2636 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.6745, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2637 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2301, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2638 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8141, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2639 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2640 of 3500\n",
      "INFO:root:single iteration took 1.663 seconds\n",
      "INFO:root:Training is 75 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.8104, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2640 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6637, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2641 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5765, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2642 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1621, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2643 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2644 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4058, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2645 took 1.711 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2738, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2646 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0268, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2647 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7814, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2648 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7422, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2649 took 1.841 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2650 of 3500\n",
      "INFO:root:single iteration took 1.681 seconds\n",
      "INFO:root:Training is 75 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.0504, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2650 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.4873, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2651 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7530, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2652 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3713, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2653 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3884, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2654 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9801, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2655 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0144, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2656 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.4802, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2657 took 1.755 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0086, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2658 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2973, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2659 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2660 of 3500\n",
      "INFO:root:single iteration took 1.694 seconds\n",
      "INFO:root:Training is 76 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.8632, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2660 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.1927, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2661 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2400, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2662 took 1.711 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9657, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2663 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8498, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2664 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5554, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2665 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7691, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2666 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8506, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2667 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1765, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2668 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4763, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2669 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2670 of 3500\n",
      "INFO:root:single iteration took 1.726 seconds\n",
      "INFO:root:Training is 76 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.2409, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2670 took 1.726 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.3385, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2671 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2672 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.0472, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2673 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2695, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2674 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6831, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2675 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(108.2816, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2676 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.0360, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2677 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4542, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2678 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7532, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2679 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2680 of 3500\n",
      "INFO:root:single iteration took 1.680 seconds\n",
      "INFO:root:Training is 76 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.1137, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2680 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5945, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2681 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.1809, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2682 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3484, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2683 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.7255, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2684 took 1.709 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.2648, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2685 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9104, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2686 took 1.735 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5183, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2687 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5972, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2688 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.1039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2689 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2690 of 3500\n",
      "INFO:root:single iteration took 1.710 seconds\n",
      "INFO:root:Training is 76 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.2229, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2690 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.3328, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2691 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6549, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2692 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2814, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2693 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9928, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2694 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9231, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2695 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6676, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2696 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9717, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2697 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7616, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2698 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.4744, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2699 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2700 of 3500\n",
      "INFO:root:single iteration took 1.691 seconds\n",
      "INFO:root:Training is 77 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(130.1112, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2700 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9041, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2701 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0444, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2702 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8909, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2703 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.0087, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2704 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1162, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2705 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0716, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2706 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7887, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2707 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7147, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2708 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.1215, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2709 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2710 of 3500\n",
      "INFO:root:single iteration took 1.675 seconds\n",
      "INFO:root:Training is 77 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.5122, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2710 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5036, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2711 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2168, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2712 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3268, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2713 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7866, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2714 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2891, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2715 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.3642, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2716 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4155, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2717 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8322, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2718 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.9370, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2719 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2720 of 3500\n",
      "INFO:root:single iteration took 1.692 seconds\n",
      "INFO:root:Training is 77 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.9010, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2720 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.3259, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2721 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2065, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2722 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.2389, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2723 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.1947, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2724 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0602, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2725 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3711, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2726 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.4659, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2727 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.0312, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2728 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8763, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2729 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2730 of 3500\n",
      "INFO:root:single iteration took 1.663 seconds\n",
      "INFO:root:Training is 78 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.1041, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2730 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.8950, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2731 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.4776, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2732 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.3951, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2733 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4773, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2734 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2735 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5670, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2736 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0098, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2737 took 1.865 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7633, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2738 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6237, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2739 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2740 of 3500\n",
      "INFO:root:single iteration took 1.682 seconds\n",
      "INFO:root:Training is 78 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.2807, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2740 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0397, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2741 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0607, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2742 took 1.727 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7953, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2743 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.0911, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2744 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8754, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2745 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.9170, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2746 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.2407, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2747 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8916, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2748 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6486, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2749 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2750 of 3500\n",
      "INFO:root:single iteration took 1.670 seconds\n",
      "INFO:root:Training is 78 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.9059, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2750 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2908, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2751 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5486, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2752 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6815, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2753 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2754 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.5763, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2755 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0871, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2756 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.9065, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2757 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8420, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2758 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8573, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2759 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2760 of 3500\n",
      "INFO:root:single iteration took 1.666 seconds\n",
      "INFO:root:Training is 78 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.0783, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2760 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.4479, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2761 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8181, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2762 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3151, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2763 took 1.756 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4599, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2764 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.8221, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2765 took 1.745 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6624, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2766 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5558, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2767 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3851, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2768 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5425, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2769 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2770 of 3500\n",
      "INFO:root:single iteration took 1.679 seconds\n",
      "INFO:root:Training is 79 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(133.3929, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2770 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4410, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2771 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.3589, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2772 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.8877, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2773 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3547, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2774 took 1.736 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6693, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2775 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4105, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2776 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.0626, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2777 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7097, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2778 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4267, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2779 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2780 of 3500\n",
      "INFO:root:single iteration took 1.707 seconds\n",
      "INFO:root:Training is 79 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.6434, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2780 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5169, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2781 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8021, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2782 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1249, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2783 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2570, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2784 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7069, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2785 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.7742, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2786 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7261, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2787 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6016, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2788 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9754, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2789 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2790 of 3500\n",
      "INFO:root:single iteration took 1.708 seconds\n",
      "INFO:root:Training is 79 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(122.5110, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2790 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1957, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2791 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6147, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2792 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2793 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5223, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2794 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.1937, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2795 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5191, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2796 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.4132, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2797 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9523, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2798 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2924, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2799 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2800 of 3500\n",
      "INFO:root:single iteration took 1.645 seconds\n",
      "INFO:root:Training is 80 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.2024, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2800 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1463, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2801 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0040, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2802 took 1.793 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.3800, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2803 took 1.625 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1231, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2804 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4508, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2805 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8420, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2806 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.5509, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2807 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9904, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2808 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1527, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2809 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2810 of 3500\n",
      "INFO:root:single iteration took 1.651 seconds\n",
      "INFO:root:Training is 80 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.7123, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2810 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6499, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2811 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3135, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2812 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2813 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7955, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2814 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.6373, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2815 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3334, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2816 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9131, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2817 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3986, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2818 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.1547, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2819 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2820 of 3500\n",
      "INFO:root:single iteration took 1.668 seconds\n",
      "INFO:root:Training is 80 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.7201, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2820 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9716, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2821 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6132, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2822 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8162, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2823 took 1.723 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5480, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2824 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5622, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2825 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7856, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2826 took 1.712 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0424, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2827 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2097, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2828 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3862, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2829 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2830 of 3500\n",
      "INFO:root:single iteration took 1.643 seconds\n",
      "INFO:root:Training is 80 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.1763, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2830 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6997, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2831 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0114, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2832 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3011, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2833 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5113, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2834 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2290, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2835 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.2158, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2836 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3935, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2837 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7627, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2838 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2721, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2839 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2840 of 3500\n",
      "INFO:root:single iteration took 1.665 seconds\n",
      "INFO:root:Training is 81 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.3686, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2840 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1613, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2841 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5311, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2842 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8106, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2843 took 1.723 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.4645, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2844 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0009, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2845 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.3249, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2846 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.7768, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2847 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3867, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2848 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.7038, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2849 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2850 of 3500\n",
      "INFO:root:single iteration took 1.661 seconds\n",
      "INFO:root:Training is 81 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.0160, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2850 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5181, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2851 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2561, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2852 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7100, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2853 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.8696, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2854 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.5780, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2855 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.7421, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2856 took 1.721 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.4678, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2857 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(133.0683, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2858 took 1.739 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.8538, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2859 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2860 of 3500\n",
      "INFO:root:single iteration took 1.660 seconds\n",
      "INFO:root:Training is 81 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.6035, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2860 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6697, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2861 took 1.623 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2796, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2862 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7995, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2863 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9716, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2864 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6953, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2865 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.4753, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2866 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3676, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2867 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5437, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2868 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5423, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2869 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2870 of 3500\n",
      "INFO:root:single iteration took 1.662 seconds\n",
      "INFO:root:Training is 82 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.3433, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2870 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4311, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2871 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1248, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2872 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3043, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2873 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.4650, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2874 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6669, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2875 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.7602, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2876 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.1383, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2877 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4542, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2878 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3220, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2879 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2880 of 3500\n",
      "INFO:root:single iteration took 1.691 seconds\n",
      "INFO:root:Training is 82 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.2748, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2880 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.1418, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2881 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1312, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2882 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9632, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2883 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2884 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8135, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2885 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2450, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2886 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1028, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2887 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2888 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7861, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2889 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2890 of 3500\n",
      "INFO:root:single iteration took 1.660 seconds\n",
      "INFO:root:Training is 82 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.3581, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2890 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8995, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2891 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4983, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2892 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.2031, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2893 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3944, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2894 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.7854, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2895 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.2676, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2896 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9154, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2897 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4310, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2898 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9324, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2899 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2900 of 3500\n",
      "INFO:root:single iteration took 1.674 seconds\n",
      "INFO:root:Training is 82 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.3630, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2900 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.8751, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2901 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5046, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2902 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8862, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2903 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6412, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2904 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8333, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2905 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2906 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8690, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2907 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.8421, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2908 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6226, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2909 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2910 of 3500\n",
      "INFO:root:single iteration took 1.707 seconds\n",
      "INFO:root:Training is 83 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.2351, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2910 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2542, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2911 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6324, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2912 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.5173, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2913 took 1.717 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7546, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2914 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6495, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2915 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5100, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2916 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.8161, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2917 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4339, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2918 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5937, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2919 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2920 of 3500\n",
      "INFO:root:single iteration took 1.705 seconds\n",
      "INFO:root:Training is 83 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.3458, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2920 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.4728, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2921 took 1.711 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(109.2346, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2922 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.2374, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2923 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5127, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2924 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9397, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2925 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7376, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2926 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.5500, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2927 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8898, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2928 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.4186, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2929 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2930 of 3500\n",
      "INFO:root:single iteration took 1.665 seconds\n",
      "INFO:root:Training is 83 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(111.6107, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2930 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(108.2962, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2931 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.3820, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2932 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8553, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2933 took 1.725 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.3574, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2934 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4991, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2935 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(107.6290, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2936 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5893, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2937 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.5613, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2938 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9396, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2939 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2940 of 3500\n",
      "INFO:root:single iteration took 1.687 seconds\n",
      "INFO:root:Training is 84 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(125.2538, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2940 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.4788, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2941 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2358, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2942 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7534, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2943 took 1.627 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6148, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2944 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9535, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2945 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(109.7160, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2946 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6868, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2947 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8684, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2948 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1911, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2949 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2950 of 3500\n",
      "INFO:root:single iteration took 1.691 seconds\n",
      "INFO:root:Training is 84 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(110.5496, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2950 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2680, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2951 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.4072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2952 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8318, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2953 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.7109, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2954 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.0714, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2955 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2956 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4367, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2957 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.3996, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2958 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6100, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2959 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2960 of 3500\n",
      "INFO:root:single iteration took 1.662 seconds\n",
      "INFO:root:Training is 84 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.0305, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2960 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4289, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2961 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.0443, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2962 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6436, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2963 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.7688, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2964 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2035, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2965 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9643, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2966 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0732, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2967 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.4332, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2968 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2098, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2969 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2970 of 3500\n",
      "INFO:root:single iteration took 1.680 seconds\n",
      "INFO:root:Training is 84 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.4143, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2970 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.2923, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2971 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4279, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2972 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.7386, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2973 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8654, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2974 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.4937, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2975 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6666, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2976 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3344, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2977 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2295, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2978 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5033, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2979 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2980 of 3500\n",
      "INFO:root:single iteration took 1.651 seconds\n",
      "INFO:root:Training is 85 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(125.2726, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2980 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9001, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2981 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3724, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2982 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2646, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2983 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3128, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2984 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.0488, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2985 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8848, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2986 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3983, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2987 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1397, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2988 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.1232, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2989 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 2990 of 3500\n",
      "INFO:root:single iteration took 1.637 seconds\n",
      "INFO:root:Training is 85 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.3090, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2990 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1896, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2991 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.6339, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2992 took 1.709 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.6858, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2993 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.9258, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2994 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.6625, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2995 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8389, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2996 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2997 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6361, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2998 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2340, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 2999 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1551, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3000 took 1.655 seconds\n",
      "logging train loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3000 of 3500\n",
      "INFO:root:single iteration took 1.655 seconds\n",
      "INFO:root:Training is 85 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0301, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3001 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3105, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3002 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.5150, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3003 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7202, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3004 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1232, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3005 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8943, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3006 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1685, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3007 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.3359, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3008 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5921, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3009 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3010 of 3500\n",
      "INFO:root:single iteration took 1.697 seconds\n",
      "INFO:root:Training is 86 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.7593, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3010 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0845, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3011 took 1.637 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6575, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3012 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0643, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3013 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6437, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3014 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8717, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3015 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.3170, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3016 took 1.876 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2032, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3017 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8176, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3018 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3538, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3019 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3020 of 3500\n",
      "INFO:root:single iteration took 1.645 seconds\n",
      "INFO:root:Training is 86 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.4351, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3020 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3564, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3021 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8338, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3022 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0835, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3023 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.8474, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3024 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.4129, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3025 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8152, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3026 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8179, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3027 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5573, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3028 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8979, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3029 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3030 of 3500\n",
      "INFO:root:single iteration took 1.927 seconds\n",
      "INFO:root:Training is 86 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.7012, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3030 took 1.927 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2206, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3031 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9621, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3032 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3011, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3033 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1776, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3034 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6171, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3035 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.3911, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3036 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8652, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3037 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.3840, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3038 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5764, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3039 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3040 of 3500\n",
      "INFO:root:single iteration took 1.669 seconds\n",
      "INFO:root:Training is 86 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.2443, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3040 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8887, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3041 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8731, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3042 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6958, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3043 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9119, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3044 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.2735, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3045 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6232, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3046 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6755, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3047 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.4224, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3048 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7196, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3049 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3050 of 3500\n",
      "INFO:root:single iteration took 1.696 seconds\n",
      "INFO:root:Training is 87 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.0455, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3050 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7274, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3051 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.9994, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3052 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.1065, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3053 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.8727, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3054 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.4989, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3055 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4249, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3056 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.6715, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3057 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1358, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3058 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.3431, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3059 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3060 of 3500\n",
      "INFO:root:single iteration took 1.680 seconds\n",
      "INFO:root:Training is 87 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.2627, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3060 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7720, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3061 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4420, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3062 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3130, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3063 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4200, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3064 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2296, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3065 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8410, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3066 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4869, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3067 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8691, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3068 took 1.726 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5094, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3069 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3070 of 3500\n",
      "INFO:root:single iteration took 1.690 seconds\n",
      "INFO:root:Training is 87 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.6691, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3070 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6616, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3071 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.0967, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3072 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.9325, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3073 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.4014, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3074 took 1.765 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7132, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3075 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.3904, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3076 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5231, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3077 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.3949, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3078 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8518, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3079 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3080 of 3500\n",
      "INFO:root:single iteration took 1.676 seconds\n",
      "INFO:root:Training is 88 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.7491, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3080 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0725, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3081 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8084, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3082 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0179, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3083 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8828, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3084 took 1.769 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1754, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3085 took 1.709 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0797, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3086 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0099, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3087 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3749, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3088 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.4285, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3089 took 1.817 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3090 of 3500\n",
      "INFO:root:single iteration took 1.676 seconds\n",
      "INFO:root:Training is 88 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.8772, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3090 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7845, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3091 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3092 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6329, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3093 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.4379, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3094 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3095 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.5893, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3096 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6717, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3097 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4350, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3098 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.4225, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3099 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3100 of 3500\n",
      "INFO:root:single iteration took 1.697 seconds\n",
      "INFO:root:Training is 88 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(132.4088, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3100 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.7253, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3101 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7824, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3102 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.8338, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3103 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1133, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3104 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1718, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3105 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.0782, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3106 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6662, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3107 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.4220, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3108 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2619, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3109 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3110 of 3500\n",
      "INFO:root:single iteration took 1.647 seconds\n",
      "INFO:root:Training is 88 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.7585, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3110 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1185, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3111 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.1219, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3112 took 1.629 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7027, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3113 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7735, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3114 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6418, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3115 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.4646, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3116 took 1.721 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(152.8010, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3117 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.5297, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3118 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.5162, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3119 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3120 of 3500\n",
      "INFO:root:single iteration took 1.673 seconds\n",
      "INFO:root:Training is 89 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(117.0895, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3120 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0922, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3121 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.8124, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3122 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9431, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3123 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8943, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3124 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(106.0320, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3125 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.7210, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3126 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3127 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7125, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3128 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.3063, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3129 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3130 of 3500\n",
      "INFO:root:single iteration took 1.684 seconds\n",
      "INFO:root:Training is 89 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(122.4773, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3130 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.3573, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3131 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.2554, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3132 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7322, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3133 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3134 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9324, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3135 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9740, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3136 took 1.697 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5839, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3137 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4217, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3138 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2154, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3139 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3140 of 3500\n",
      "INFO:root:single iteration took 1.674 seconds\n",
      "INFO:root:Training is 89 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.5448, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3140 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.9993, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3141 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9808, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3142 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8739, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3143 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1742, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3144 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5831, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3145 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9321, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3146 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7033, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3147 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5110, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3148 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.3855, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3149 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3150 of 3500\n",
      "INFO:root:single iteration took 1.661 seconds\n",
      "INFO:root:Training is 90 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.5677, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3150 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.1501, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3151 took 1.720 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.5287, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3152 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.5282, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3153 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.4767, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3154 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8863, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3155 took 1.717 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.2313, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3156 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.0832, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3157 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.9039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3158 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4537, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3159 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3160 of 3500\n",
      "INFO:root:single iteration took 1.683 seconds\n",
      "INFO:root:Training is 90 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.8356, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3160 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6801, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3161 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.0298, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3162 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5253, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3163 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8061, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3164 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3009, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3165 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8028, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3166 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.6465, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3167 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2924, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3168 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0397, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3169 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3170 of 3500\n",
      "INFO:root:single iteration took 1.674 seconds\n",
      "INFO:root:Training is 90 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(112.2523, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3170 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2457, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3171 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.0916, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3172 took 1.727 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8945, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3173 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.1795, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3174 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3347, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3175 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.8596, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3176 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8549, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3177 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.6198, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3178 took 1.639 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2408, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3179 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3180 of 3500\n",
      "INFO:root:single iteration took 1.720 seconds\n",
      "INFO:root:Training is 90 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.9807, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3180 took 1.720 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1814, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3181 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0062, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3182 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5096, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3183 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.4712, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3184 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0595, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3185 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6505, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3186 took 1.707 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0940, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3187 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5010, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3188 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2964, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3189 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3190 of 3500\n",
      "INFO:root:single iteration took 1.691 seconds\n",
      "INFO:root:Training is 91 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(118.8427, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3190 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2123, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3191 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1869, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3192 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8686, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3193 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2743, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3194 took 1.765 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5659, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3195 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3317, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3196 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8549, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3197 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2895, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3198 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5286, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3199 took 1.691 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3200 of 3500\n",
      "INFO:root:single iteration took 1.699 seconds\n",
      "INFO:root:Training is 91 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(127.2195, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3200 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9292, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3201 took 1.709 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.7234, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3202 took 1.743 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.8790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3203 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3654, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3204 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5132, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3205 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2092, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3206 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7476, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3207 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3132, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3208 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1718, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3209 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3210 of 3500\n",
      "INFO:root:single iteration took 1.683 seconds\n",
      "INFO:root:Training is 91 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(125.4846, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3210 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6419, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3211 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4498, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3212 took 1.714 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9390, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3213 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9018, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3214 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0783, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3215 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.3881, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3216 took 1.722 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0671, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3217 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.4043, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3218 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3304, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3219 took 1.723 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3220 of 3500\n",
      "INFO:root:single iteration took 1.705 seconds\n",
      "INFO:root:Training is 92 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(122.9014, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3220 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.1912, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3221 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.7456, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3222 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.6629, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3223 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.7823, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3224 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9764, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3225 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8819, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3226 took 1.720 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3227 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2687, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3228 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(135.9075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3229 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3230 of 3500\n",
      "INFO:root:single iteration took 1.671 seconds\n",
      "INFO:root:Training is 92 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(111.8233, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3230 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2741, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3231 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.4749, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3232 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2916, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3233 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.4380, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3234 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8505, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3235 took 1.716 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7743, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3236 took 1.724 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.3711, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3237 took 1.794 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2886, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3238 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7649, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3239 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3240 of 3500\n",
      "INFO:root:single iteration took 1.678 seconds\n",
      "INFO:root:Training is 92 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.2567, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3240 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9241, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3241 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.7416, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3242 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.6063, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3243 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.2198, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3244 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.0930, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3245 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6418, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3246 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9756, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3247 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7279, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3248 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0673, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3249 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3250 of 3500\n",
      "INFO:root:single iteration took 1.690 seconds\n",
      "INFO:root:Training is 92 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.1624, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3250 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1243, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3251 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.6009, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3252 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7385, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3253 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0924, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3254 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.5657, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3255 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.8000, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3256 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6945, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3257 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3640, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3258 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.4744, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3259 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3260 of 3500\n",
      "INFO:root:single iteration took 1.658 seconds\n",
      "INFO:root:Training is 93 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(120.1743, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3260 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6020, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3261 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5459, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3262 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6622, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3263 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.4600, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3264 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4874, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3265 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9588, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3266 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9493, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3267 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.0224, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3268 took 1.828 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3047, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3269 took 1.776 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3270 of 3500\n",
      "INFO:root:single iteration took 1.671 seconds\n",
      "INFO:root:Training is 93 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.9455, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3270 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4537, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3271 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.1849, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3272 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8190, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3273 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(131.9084, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3274 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.5291, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3275 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7174, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3276 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.4297, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3277 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6155, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3278 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.4630, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3279 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3280 of 3500\n",
      "INFO:root:single iteration took 1.665 seconds\n",
      "INFO:root:Training is 93 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(110.4370, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3280 took 1.665 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.9374, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3281 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.7935, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3282 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.4648, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3283 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.8508, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3284 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6110, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3285 took 1.638 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2563, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3286 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.7601, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3287 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(130.2090, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3288 took 1.745 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.5959, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3289 took 1.651 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3290 of 3500\n",
      "INFO:root:single iteration took 1.728 seconds\n",
      "INFO:root:Training is 94 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.7417, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3290 took 1.728 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4304, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3291 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.0757, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3292 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(136.9078, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3293 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.7158, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3294 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1391, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3295 took 1.710 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.5704, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3296 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4255, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3297 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3298 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3350, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3299 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3300 of 3500\n",
      "INFO:root:single iteration took 1.701 seconds\n",
      "INFO:root:Training is 94 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.7399, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3300 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0844, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3301 took 1.720 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4909, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3302 took 1.749 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.2972, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3303 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6716, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3304 took 1.795 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6312, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3305 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.8797, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3306 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.3513, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3307 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3695, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3308 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(108.0932, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3309 took 1.659 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3310 of 3500\n",
      "INFO:root:single iteration took 1.670 seconds\n",
      "INFO:root:Training is 94 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(111.9458, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3310 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(109.7913, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3311 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(108.9914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3312 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1401, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3313 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6685, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3314 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.2446, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3315 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.7567, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3316 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.1512, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3317 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.2220, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3318 took 1.713 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.9697, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3319 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3320 of 3500\n",
      "INFO:root:single iteration took 1.661 seconds\n",
      "INFO:root:Training is 94 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(121.1125, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3320 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.4578, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3321 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1707, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3322 took 1.635 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.8191, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3323 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.2949, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3324 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5974, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3325 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(109.2885, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3326 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4372, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3327 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5804, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3328 took 1.662 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6171, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3329 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3330 of 3500\n",
      "INFO:root:single iteration took 1.678 seconds\n",
      "INFO:root:Training is 95 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.1137, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3330 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.3220, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3331 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.2619, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3332 took 1.745 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.6919, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3333 took 1.672 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4625, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3334 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.0089, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3335 took 1.631 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.3134, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3336 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.6668, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3337 took 1.674 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.8122, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3338 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.2366, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3339 took 1.689 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3340 of 3500\n",
      "INFO:root:single iteration took 1.706 seconds\n",
      "INFO:root:Training is 95 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(111.5451, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3340 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.0962, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3341 took 1.684 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(129.8645, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3342 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3234, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3343 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1718, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3344 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6458, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3345 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.8973, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3346 took 1.702 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.8674, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3347 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.4992, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3348 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.1446, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3349 took 1.636 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3350 of 3500\n",
      "INFO:root:single iteration took 1.652 seconds\n",
      "INFO:root:Training is 95 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(111.3578, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3350 took 1.652 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.1472, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3351 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7625, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3352 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1323, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3353 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.2691, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3354 took 1.619 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.2717, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3355 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5837, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3356 took 1.582 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3357 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9471, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3358 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6154, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3359 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3360 of 3500\n",
      "INFO:root:single iteration took 1.680 seconds\n",
      "INFO:root:Training is 96 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(125.4268, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3360 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8807, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3361 took 1.624 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1624, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3362 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4609, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3363 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3437, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3364 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9473, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3365 took 1.768 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7123, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3366 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7930, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3367 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.8124, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3368 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(132.5056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3369 took 1.721 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3370 of 3500\n",
      "INFO:root:single iteration took 1.693 seconds\n",
      "INFO:root:Training is 96 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(116.8914, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3370 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.9718, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3371 took 1.756 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4918, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3372 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.0250, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3373 took 1.727 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0785, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3374 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8962, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3375 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.2929, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3376 took 1.717 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.7439, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3377 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2452, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3378 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.8475, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3379 took 1.735 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3380 of 3500\n",
      "INFO:root:single iteration took 1.725 seconds\n",
      "INFO:root:Training is 96 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(123.4289, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3380 took 1.725 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1503, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3381 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.3806, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3382 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.1932, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3383 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6627, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3384 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9452, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3385 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.1685, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3386 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7311, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3387 took 1.663 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5143, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3388 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.9731, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3389 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3390 of 3500\n",
      "INFO:root:single iteration took 1.703 seconds\n",
      "INFO:root:Training is 96 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.6415, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3390 took 1.703 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(124.3362, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3391 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.0282, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3392 took 1.673 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.2618, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3393 took 1.657 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(140.0859, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3394 took 1.650 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1686, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3395 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.7951, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3396 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.6923, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3397 took 1.722 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5723, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3398 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3479, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3399 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3400 of 3500\n",
      "INFO:root:single iteration took 1.688 seconds\n",
      "INFO:root:Training is 97 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.5496, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3400 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1465, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3401 took 1.694 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.9472, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3402 took 1.685 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.6287, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3403 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4898, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3404 took 1.698 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.3022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3405 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0963, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3406 took 1.681 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.5764, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3407 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.5823, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3408 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2861, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3409 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3410 of 3500\n",
      "INFO:root:single iteration took 1.705 seconds\n",
      "INFO:root:Training is 97 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(127.0709, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3410 took 1.705 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.7502, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3411 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.9059, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3412 took 1.688 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7982, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3413 took 1.669 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.7567, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3414 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0306, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3415 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(128.2697, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3416 took 1.696 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0606, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3417 took 1.821 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.6722, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3418 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.4265, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3419 took 1.675 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3420 of 3500\n",
      "INFO:root:single iteration took 1.670 seconds\n",
      "INFO:root:Training is 97 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(113.7358, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3420 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.3016, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3421 took 1.648 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.4268, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3422 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.2856, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3423 took 1.676 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8037, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3424 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1721, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3425 took 1.757 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.3648, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3426 took 1.720 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.1190, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3427 took 1.701 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4701, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3428 took 1.790 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9709, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3429 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3430 of 3500\n",
      "INFO:root:single iteration took 1.797 seconds\n",
      "INFO:root:Training is 98 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(114.5734, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3430 took 1.797 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.9039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3431 took 1.741 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.5165, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3432 took 1.680 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(376.3009, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3433 took 1.714 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(125.2900, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3434 took 1.736 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5982, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3435 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.0509, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3436 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0998, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3437 took 1.630 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.6483, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3438 took 1.658 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.6134, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3439 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3440 of 3500\n",
      "INFO:root:single iteration took 1.644 seconds\n",
      "INFO:root:Training is 98 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(115.0262, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3440 took 1.644 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8931, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3441 took 1.700 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7790, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3442 took 1.706 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8832, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3443 took 1.699 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0778, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3444 took 1.690 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.3481, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3445 took 1.671 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.2794, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3446 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.0225, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3447 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.9951, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3448 took 1.660 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.2092, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3449 took 1.653 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3450 of 3500\n",
      "INFO:root:single iteration took 1.704 seconds\n",
      "INFO:root:Training is 98 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.9894, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3450 took 1.704 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(110.4807, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3451 took 1.708 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.5325, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3452 took 1.642 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(127.3451, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3453 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.9418, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3454 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8347, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3455 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(120.2288, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3456 took 1.633 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.4933, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3457 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.4704, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3458 took 1.666 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6540, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3459 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3460 of 3500\n",
      "INFO:root:single iteration took 1.654 seconds\n",
      "INFO:root:Training is 98 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.6217, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3460 took 1.654 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.8051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3461 took 1.647 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4365, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3462 took 1.695 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.1725, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3463 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.4517, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3464 took 1.643 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.1614, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3465 took 1.656 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.2457, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3466 took 1.724 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.4102, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3467 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8897, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3468 took 1.626 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.0596, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3469 took 1.712 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3470 of 3500\n",
      "INFO:root:single iteration took 1.668 seconds\n",
      "INFO:root:Training is 99 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(111.6167, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3470 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.2257, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3471 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.7347, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3472 took 1.634 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.7202, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3473 took 1.661 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(122.1156, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3474 took 1.677 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.0109, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3475 took 1.655 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(121.5952, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3476 took 1.725 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(123.8945, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3477 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.9726, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3478 took 1.715 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5920, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3479 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3480 of 3500\n",
      "INFO:root:single iteration took 1.667 seconds\n",
      "INFO:root:Training is 99 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(119.5270, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3480 took 1.667 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.5442, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3481 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(112.8636, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3482 took 1.687 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.7104, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3483 took 1.649 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.6058, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3484 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(117.8526, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3485 took 1.782 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.8382, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3486 took 1.645 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(119.0201, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3487 took 1.679 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.0919, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3488 took 1.664 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.6859, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3489 took 1.646 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3490 of 3500\n",
      "INFO:root:single iteration took 1.668 seconds\n",
      "INFO:root:Training is 99 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(124.8304, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3490 took 1.668 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.0340, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3491 took 1.641 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(115.8735, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3492 took 1.640 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(114.5033, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3493 took 1.692 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.8366, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3494 took 1.670 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.5240, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3495 took 1.678 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(118.3941, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3496 took 1.682 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.8940, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3497 took 1.686 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(116.4295, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3498 took 1.693 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(126.3557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3499 took 1.683 seconds\n",
      "logging train loss\n",
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(113.4335, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3500 took 1.659 seconds\n",
      "logging train loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training on iteration 3500 of 3500\n",
      "INFO:root:single iteration took 1.659 seconds\n",
      "INFO:root:Training is 100 percent complete\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same scene, same object\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "loss: tensor(111.5171, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "iteration 3501 took 1.668 seconds\n",
      "logging train loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Finished testing after 3500 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training descriptor of dimension 3\n"
     ]
    }
   ],
   "source": [
    "# All of the saved data for this network will be located in the\n",
    "# code/data_volume/pdc/trained_models/tutorials/caterpillar_3 folder\n",
    "\n",
    "if TRAIN:\n",
    "    print \"training descriptor of dimension %d\" %(d)\n",
    "    train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "    train.run()\n",
    "    print \"finished training descriptor of dimension %d\" %(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got /home/adi/code/data_volume/fabric_data/trained_models/tutorials/tier3_oracle_1824_3\n",
      "got output_dir\n",
      "got train_output_dir /home/adi/code/data_volume/fabric_data/trained_models/tutorials/tier3_oracle_1824_3/analysis/train\n",
      "got test_output_dir /home/adi/code/data_volume/fabric_data/trained_models/tutorials/tier3_oracle_1824_3/analysis/test\n",
      "got cross_scene_output_dir /home/adi/code/data_volume/fabric_data/trained_models/tutorials/tier3_oracle_1824_3/analysis/cross_scene\n",
      "making necessary dirs\n",
      "model_param_file 003501.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing descriptor statistics on dataset\n",
      "INFO:root:Loading knots info for scene tier3_oracle_1824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene directory: /home/adi/code/data_volume/fabric_data/logs_proto/tier3_oracle_1824/processed\n",
      "Using SpartanDataset:\n",
      "   - in train mode\n",
      "   - number of scenes 1\n",
      "   - total images:     1825\n",
      "computing stats\n",
      "doing dcn eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:2562: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating network on train data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing descriptor norm\n",
      "done computing stats\n",
      "computing statistics for image 0 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 5 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 10 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 15 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 20 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 25 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 30 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 35 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 40 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 45 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 50 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 55 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 60 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 65 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 70 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 75 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 80 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 85 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 90 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 95 of 100, scene_name tier3_oracle_1824\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating network on test data\n",
      "INFO:root:Loading knots info for scene tier3_oracle_1824_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing statistics for image 0 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 5 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 10 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 15 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 20 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 25 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 30 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 35 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 40 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 45 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 50 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 55 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 60 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 65 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 70 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 75 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 80 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 85 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 90 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "computing statistics for image 95 of 100, scene_name tier3_oracle_1824_test\n",
      "scene\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n",
      "normalizing descriptor norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Making plots\n",
      "INFO:root:Finished running evaluation on network\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_to_absolute_path(model_folder)\n",
    "\n",
    "if True: #EVALUATE\n",
    "    DCE = DenseCorrespondenceEvaluation\n",
    "    num_image_pairs = 100\n",
    "    DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `evaluation_quantitative_tutorial.ipynb` for a better place to display the plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
